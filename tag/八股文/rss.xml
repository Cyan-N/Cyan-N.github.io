<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>慕青の迷途 • Posts by &#34;八股文&#34; tag</title>
        <link>https://cecilia.cool</link>
        <description>时雨病重症患者</description>
        <language>zh-CN</language>
        <pubDate>Mon, 24 Jul 2023 10:35:41 +0800</pubDate>
        <lastBuildDate>Mon, 24 Jul 2023 10:35:41 +0800</lastBuildDate>
        <category>Docker</category>
        <category>shell</category>
        <category>tools</category>
        <category>二次元</category>
        <category>云计算</category>
        <category>八股文</category>
        <category>前端</category>
        <category>操作系统</category>
        <category>数据结构与算法</category>
        <category>网络协议与工具</category>
        <category>MySQL</category>
        <category>Redis</category>
        <category>Concurrency</category>
        <category>Spring全家桶</category>
        <category>uni-app</category>
        <category>JVM</category>
        <category>Mybatis</category>
        <category>Java基础</category>
        <category>设计模式</category>
        <category>Java8</category>
        <category>Web</category>
        <category>网络编程</category>
        <category>Projects</category>
        <category>消息队列</category>
        <category>408</category>
        <item>
            <guid isPermalink="true">https://cecilia.cool/2023/07/24/%E5%85%AB%E8%82%A1%E6%96%87/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid>
            <title>操作系统</title>
            <link>https://cecilia.cool/2023/07/24/%E5%85%AB%E8%82%A1%E6%96%87/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
            <category>八股文</category>
            <pubDate>Mon, 24 Jul 2023 10:35:41 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;硬件设备&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#硬件设备&#34;&gt;#&lt;/a&gt; 硬件设备&lt;/h1&gt;
&lt;h2 id=&#34;存储&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#存储&#34;&gt;#&lt;/a&gt; 存储&lt;/h2&gt;
&lt;p&gt;存储结构分为：缓存、内存、磁盘&lt;/p&gt;
&lt;p&gt;缓存：L1 cache、L2 cache、L3cache。其中，L1 和 L2 每个 CPU 都有，L3 被所有 CPU 共享。&lt;/p&gt;
&lt;p&gt;缓存中，以行为单位，即缓存行（cache line），每一行分为有效位、头标志 Tag、数据块 Data Block。一般来说，cache line 大小为 64 字节，任何一个字节上的变量发生变化，就会导致缓存行失效，所以设计程序时应该注意&lt;strong&gt;伪共享问题&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;CPU 如何知道缓存行中是否有需要的内存数据？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;内存的数据和缓存行的数据存在映射关系，不同的映射算法会导致不同的映射规则。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;直接映射&lt;/strong&gt;：内存地址【Tag+Index+Offset】，内存地址的 Index 取模看落到哪个 cache line，然后查看 cache line 的有效位是否有效，再比较 Tag 是否相同，最后通过 Offset 拿到该数据在缓存行中的数据。&lt;/p&gt;
&lt;h2 id=&#34;cpu&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#cpu&#34;&gt;#&lt;/a&gt; CPU&lt;/h2&gt;
&lt;p&gt;分支预测器：&lt;strong&gt;如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;对于代码：&lt;/p&gt;
&lt;figure class=&#34;highlight java&#34;&gt;&lt;figcaption data-lang=&#34;java&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;int&lt;/span&gt; arr&lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;token class-name&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token keyword&#34;&gt;int&lt;/span&gt; i &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; i &lt;span class=&#34;token operator&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; i&lt;span class=&#34;token operator&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    arr&lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;i&lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;token comment&#34;&gt;// 赋值 0~100&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;6&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token comment&#34;&gt;// 操作 A&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;7&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token keyword&#34;&gt;int&lt;/span&gt; i &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; i &lt;span class=&#34;token operator&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; i&lt;span class=&#34;token operator&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;8&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;arr&lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;i&lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;&gt;&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; arr&lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;i&lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;9&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;10&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;11&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token comment&#34;&gt;// 操作 B&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;12&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token function&#34;&gt;sort&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;arr&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;执行操作 A 再执行操作 B 速度比执行操作 B 再执行操作 A 慢，因为一开始 arr 是随机的，分支预测器不能很好工作，反而会出现一些无效预测，先排序再赋值，分支预测器能更好工作。&lt;/p&gt;
&lt;p&gt;CPU 存在缓存一致性问题，这就引来两个需要处理的事情：写传播和事务串行化。&lt;strong&gt;写传播&lt;/strong&gt;就是将修改的数据传给其他 CPU，而&lt;strong&gt;事务串行化&lt;/strong&gt;就是其他 CPU 拿到修改的顺序相同。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MESI 协议&lt;/strong&gt;在总线嗅探机制上，实现了 CPU 缓存一致性（单纯使用总线嗅探无法保证事务串行化）。&lt;/p&gt;
&lt;p&gt;MESI 含义为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Modified，已修改，更新了 cache line 数据后的状态，此时 cache line 数据和内存中的数据不同。之后如果该 cache line 会被替换成其他数据，就需要先同步到内存中。&lt;/li&gt;
&lt;li&gt;Exclusive，独占，数据只在该 CPU cache 中&lt;/li&gt;
&lt;li&gt;Shared，共享，数据在多个 CPU cache 中&lt;/li&gt;
&lt;li&gt;Invalidated，已失效，更新共享的数据时，先广播请求，使得其他 CPU 对应的 cache line 设置为无效，再更新 cache line 数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;表示缓存行的四种状态，具体操作必须等待缓存行成为具体状态才可以执行，假设：A 操作将缓存行状态设为 invalid，此时 B 操作也是对该缓存行的写入操作，B 操作就需要等待 A 操作完成，缓存行状态被设置为 modified 才可以执行 B 操作（设置缓存行无效等等）。&lt;/p&gt;
&lt;p&gt;因为一个缓存行的大小一般是 64 字节，所以就会存在&lt;strong&gt;伪共享&lt;/strong&gt;问题：假设 AB 两个对象占用内存比较小，位于同一个缓存行，那么当改变了 A 时，整个缓存行数据都会失效，这也导致 B 本来没有修改，但是也会失效。如果其他 CPU 的也是将 AB 放到了同一个缓存行，这个问题更严重。一般的解决方法就是填充对象，&lt;strong&gt;使得一个对象大小为 64 字节&lt;/strong&gt;。DIsruptor 框架就是用了&lt;strong&gt;字节填充 + 继承&lt;/strong&gt;的方式。在 Linux 中，还有一种宏，可以使的字节对齐，本质还是空间换时间。&lt;/p&gt;
&lt;p&gt;线程和进程在 Linux 内核中都是 &lt;code&gt;task_struct&lt;/code&gt;  结构体表示的，只不过线程的部分资源共享了进程的资源，因此承载的资源更少。但是本质都是 &lt;code&gt;task_struct&lt;/code&gt; ，Linux 中的 CPU 调度器，调度的对象就是 &lt;code&gt;task_struct&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;硬中断和软中断：硬件发出中断（硬中断），CPU 就停下当前任务并处理中断，此时会屏蔽中断（硬中断），快速处理完必要任务后，剩余的长任务（IO 操作等），通过软件指令发出软中断交给内核线程（每个 CPU 都对应一个内核线程）运行。软中断其实还包括一些内核自定义事件（内核调度、RCU 锁等）&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://cecilia.cool/2023/04/18/%E5%85%AB%E8%82%A1%E6%96%87/Mybatis/</guid>
            <title>Mybatis</title>
            <link>https://cecilia.cool/2023/04/18/%E5%85%AB%E8%82%A1%E6%96%87/Mybatis/</link>
            <category>八股文</category>
            <pubDate>Tue, 18 Apr 2023 14:06:09 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Mybatis&lt;/code&gt;  预防 sql 注入问题&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;mybatis 使用 &lt;code&gt;#&amp;#123;&amp;#125;&lt;/code&gt;  而不是 &lt;code&gt;$&amp;#123;&amp;#125;&lt;/code&gt;  可以很大程度预防 sql 注入，因为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;#&amp;#123;&amp;#125;&lt;/code&gt;  是一个参数占位符，对于字符串类型，会自动加上 &amp;quot;&amp;quot;，其他类型不加。由于 Mybatis 采用&lt;strong&gt;预编译&lt;/strong&gt;，其后的参数不会再进行 SQL 编译，所以一定程度上防止 SQL 注入。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&amp;#123;&amp;#125;&lt;/code&gt;  是一个简单的字符串替换，字符串是什么，就会解析成什么，存在 SQL 注入风险&lt;/li&gt;
&lt;/ul&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://cecilia.cool/2023/04/17/%E5%85%AB%E8%82%A1%E6%96%87/Linux/</guid>
            <title>Linux</title>
            <link>https://cecilia.cool/2023/04/17/%E5%85%AB%E8%82%A1%E6%96%87/Linux/</link>
            <category>八股文</category>
            <pubDate>Mon, 17 Apr 2023 22:46:25 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;本文大部分应该都是与 Linux 笔试题有关，因为我之前几场笔试，百度和 SNK 都遇到了 Linux 的笔试题，所以总结本文。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;chmod 和 chown 的区别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;chmod 和 chown 的主要区别在于 chmod 用于修改文件权限，而 chown 用于修改文件所有权。&lt;/p&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token function&#34;&gt;chmod&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;700&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;file&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token function&#34;&gt;chown&lt;/span&gt; newowner:newgrp &lt;span class=&#34;token function&#34;&gt;file&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;提一下文件的权限组成：700，7 表示所有者的权限，0 表示组的权限，0 表示其他人的权限。每个数其实都是 3bit，依次是&lt;strong&gt;读、写、执行&lt;/strong&gt;三种权限。 &lt;code&gt;umask&lt;/code&gt;  作为掩码，通常是 022，而文件默认权限值为 0666，0666-022=0644 才是实际的文件权限&lt;/p&gt;
&lt;p&gt;除了数字，还有符号表示法：使用 u、g、o 和 a 表示用户、组、其他人和所有人，使用 +、- 和 = 表示添加、删除和设置权限，使用 r、w 和 x 表示读、写和执行权限。&lt;/p&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption data-lang=&#34;bash&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token function&#34;&gt;chmod&lt;/span&gt; u+rwx,g+rwx,o-rwx path/to/file&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;blockquote&gt;
&lt;p&gt;du 和 df 区别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;du 是计算&lt;strong&gt;文件 / 目录&lt;/strong&gt;的磁盘使用情况，而 df 是计算文件系统磁盘空间的使用情况。二者都可以使用 - h 选项使得结果显示对人类友好。这里顺便提一下 /proc 目录，这是一个虚拟文件系统，它提供了有关系统内核和进程的信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/proc/cpuinfo: 包含有关 CPU 的信息，例如 CPU 型号、速度、缓存大小等。&lt;/li&gt;
&lt;li&gt;/proc/meminfo: 包含有关系统内存的信息，例如总内存、可用内存、缓存大小等。&lt;/li&gt;
&lt;li&gt;/proc/loadavg: 包含有关系统负载的信息，例如平均负载、运行进程数等。&lt;/li&gt;
&lt;li&gt;/proc/version: 包含有关内核版本的信息。&lt;/li&gt;
&lt;li&gt;/proc/net: 包含有关网络协议的信息，例如 TCP、UDP 等。&lt;/li&gt;
&lt;li&gt;/proc/sys: 包含有关内核参数的信息，例如文件句柄限制、TCP 缓冲区大小等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以我们可以使用 cat 命令来查看相关信息。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;sed 匹配&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;sed ‘s/AAA/BBB’ xyz 将第一个 AAA 替换为 BBB&lt;/li&gt;
&lt;li&gt;sed ‘s/AAA/BBB/g’ xyz 将全局 AAA 替换为 BBB&lt;/li&gt;
&lt;li&gt;sed ‘s/AAA/BBB/p’ xyz 将第一个 AAA 替换为 BBB，并打印替换后的那一行，这不是全局的，但是可以加上 g&lt;/li&gt;
&lt;li&gt;sed ‘s/AAA/BBB/d’ xyz，删除匹配的那一行，也不是全局的&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;uptime 命令&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;输出结果： 10:32:47 up 1 day,  2:30,  1 user,  load average: 0.00, 0.01, 0.05&lt;/p&gt;
&lt;p&gt;“up” 后面的数字表示系统已经运行的时间，以天、小时和分钟为单位。在上面的示例中，系统已经运行了 1 天 2 小时 30 分钟。&lt;/p&gt;
&lt;p&gt;查看远程 Linux 系统运行了多少时间命令：ssh user@被监控主机 ip “uptime”	含义为使用 SSH 连接到远程 Linux 系统并运行 uptime 命令。注意不是 scp，这个命令是远程 / 本地两个系统之间复制文件用的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;缺省的 shell&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Linux 缺省的 shell 为 bash，缺省就是没有指定，默认的意思。wc 这种题就不能好好说话吗？不能直接说默认的 shell 吗？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;wc 命令&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;例题为：统计一个文件中” 运维派” 出现的行数？&lt;/p&gt;
&lt;p&gt;命令为：grep “运维派” 文件名 | wc -l&lt;/p&gt;
&lt;p&gt;其中 - l 选项就是计算行数（grep 也是匹配行）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;find -newer 命令&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;直接看例子：&lt;strong&gt;find -newer file1 ! file2&lt;/strong&gt;  查找更改时间比文件 file1 新但比文件 file2 旧的文件&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;init 进程&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;若一个进程退出时，其子进程还在运行（没有被杀死），则这些子进程会变成孤儿进程（Orphan Process）。孤儿进程就会被 init 进程管理。&lt;/p&gt;
&lt;p&gt;拓展一下其他进程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;syslogd：守护进程，和记录日志有关&lt;/li&gt;
&lt;li&gt;sshd：opensshd 软件套件中的服务器守护进程&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;ls&amp;gt;c 命令&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个命令，如果没有 c 文件会先创建 c 文件，再执行 ls。假设当前目录只有 ab 两个文件，那么 ls&amp;gt;c 后 c 文件的内容为 abc&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;定义 bash 环境的用户文件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;bashrc &amp;amp;.bash_profile&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;TCP_NODELAY 参数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当有一个 TCP 数据段不足 MSS，比如要发送 700Byte 数据，MSS 为 1460Byte 的情况。nagle 算&lt;strong&gt;延迟这个数据段的发送，等待，直到有足够的数据填充成一个完整数据段。也许有人会问，这有什么影响呢？没有太大的影响，总体上来说，这种措施能节省不必要的资源消耗。但是要发送的总体数据很小时，这种措施就是拖后腿了。比如，用户请求一个网页，大约十几 KB 的数据，TCP 先发送了&lt;/strong&gt;个数据包，剩下几百字节一直不发送，要等到另一个 RTT 才发送，这时候前面发送数据的 ACK 已经返回了。这样的用户体验是很不好的。 所以，现在很多服务器都选择主动关闭 nagle 算法，因为带宽够大，资源消耗不是问题，速度反而是个大问题。&lt;/p&gt;
&lt;p&gt;在 TCP 的实现中广泛使用 Nagle 算法。&lt;br /&gt;
算法如下：若发送应用进程把要发送的数据逐个字节地送到 TCP 的发送缓存，则发送方就把第一个数据字节先发送出去，把后面到达的数据字节都缓存起来。当发送方收到对第一个数据字符的确认后，再把发送缓存中的所有数据组装成一个报文段发送出去，同时继续对随后到达的数据进行缓存。只有在收到对前一个报文段的确认后才继续发送下一个报文段。当数据到达较快而网络速率较慢时，用这样的方法可明显地减少所用的网络带宽。Nagle 算法还规定，当到达的数据已达到发送窗口大小的一半或已达到报文段的最大长度时，就立即发送一个报文段。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://cecilia.cool/2023/03/26/%E5%85%AB%E8%82%A1%E6%96%87/spring/</guid>
            <title>spring</title>
            <link>https://cecilia.cool/2023/03/26/%E5%85%AB%E8%82%A1%E6%96%87/spring/</link>
            <category>八股文</category>
            <pubDate>Sun, 26 Mar 2023 17:28:23 +0800</pubDate>
            <description><![CDATA[ &lt;blockquote&gt;
&lt;p&gt;spring 事务传播&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNDg1MDQwOTQ=&#34;&gt;https://zhuanlan.zhihu.com/p/148504094&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;spring 事务有七种传播机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;reuqired&lt;/code&gt; ：需要以事务运行，如果当前存在能在事务，则在当前事务运行，如果没有则自己开一个事务。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;required_new&lt;/code&gt; ：不管当前事务存不存在，都会新开一个事务，并且这个事务是独立的。也就是说，当前事务的回滚不会影响外部事务。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;supports&lt;/code&gt; ：当前存在事务，则加入当前事务，没有以非事务运行。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;not_supported&lt;/code&gt; ：始终以非事务方式执行，如果当前存在事务，则挂起当前事务。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mandatory&lt;/code&gt; ：强制以事务执行，当前事务不存在则抛出异常。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;never&lt;/code&gt; ：不使用事务，如果当前存在事务，抛出异常。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nested&lt;/code&gt; ：如果当前事务存在，则嵌套在该事务执行，调用方其实可以通过 catch 捕获被调用方的异常，那么当嵌套的子事务回滚时，父事务不会回滚。&lt;/li&gt;
&lt;/ul&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://cecilia.cool/2023/03/11/%E5%85%AB%E8%82%A1%E6%96%87/MySQL/</guid>
            <title>MySQL</title>
            <link>https://cecilia.cool/2023/03/11/%E5%85%AB%E8%82%A1%E6%96%87/MySQL/</link>
            <category>八股文</category>
            <pubDate>Sat, 11 Mar 2023 20:10:31 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;本文参考网上各种博客以及《MySQL 是怎样运行的》一书，特别声明的是，我并没有看过任何关于 MySQL 的源码，我所见所学，皆是站在前人的基础。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一条 &lt;code&gt;SQL&lt;/code&gt;  查询语句在 &lt;code&gt;MySQL&lt;/code&gt;  中如何执行的？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;算是一道经典面试题了，相当于计网的一条 &lt;code&gt;URL&lt;/code&gt;  从输入到界面呈现发生了什么类似。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先检查语句是否有权限，在 8.0 版本以前，有权限会先检查缓存，但是这并不是一个很好的特性，所以在 8.0 版本后删除了该操作。&lt;/li&gt;
&lt;li&gt;分析器进行词法分析，提取关键字，判断语法。&lt;/li&gt;
&lt;li&gt;执行 &lt;code&gt;sql&lt;/code&gt; ：
&lt;ol&gt;
&lt;li&gt;预处理阶段：检查查询语句的表、字段是否存在，将 &lt;code&gt;*&lt;/code&gt;  扩展为表上所有列。&lt;/li&gt;
&lt;li&gt;优化阶段：优化器生成执行方案&lt;/li&gt;
&lt;li&gt;执行阶段：执行方案交给执行器进行权限校验后执行，返回执行结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;  和 &lt;code&gt;MyISAM&lt;/code&gt;  的比较&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;事务： &lt;code&gt;InnoDB&lt;/code&gt;  是事务型的，可以使用 &lt;code&gt;Commit&lt;/code&gt;  和 &lt;code&gt;Rollback&lt;/code&gt; 。而 &lt;code&gt;MyISAM&lt;/code&gt;  不支持事务。&lt;/li&gt;
&lt;li&gt;并发： &lt;code&gt;InnoDB&lt;/code&gt;  支持行级锁，而 &lt;code&gt;MyISAM&lt;/code&gt;  支持表级锁。&lt;/li&gt;
&lt;li&gt;外键： &lt;code&gt;InnoDB&lt;/code&gt;  支持外键而 &lt;code&gt;MyISAM&lt;/code&gt;  不支持&lt;/li&gt;
&lt;li&gt;崩溃恢复： &lt;code&gt;InnoDB&lt;/code&gt;  崩溃恢复后发生损坏的概率比 &lt;code&gt;MyISAM&lt;/code&gt;  高，而且恢复速度也慢。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;InnoDB&lt;/code&gt;  更适合处理事务性应用程序，需要支持外键约束和具有高并发和可靠性； &lt;code&gt;MyISAM&lt;/code&gt;  更适合处理只读或只写的应用程序，需要较好的性能和较少的系统资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;一般如何对 &lt;code&gt;SQL&lt;/code&gt;  优化？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这种问题把你能想到的都答上去，但是尽量要有条理。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设计表方面：尽量减少字符串使用，多用数字类型；使用字符串尽量用 &lt;code&gt;varchar&lt;/code&gt;  节省空间。当索引列的重复数据占大多数时，建议删掉索引，因为使用这种索引并不会节省太多时间，相反有时回表太多导致性能下降。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SQL&lt;/code&gt;  语句方面：少使用 &lt;code&gt;select *&lt;/code&gt; ，尽量避免用 &lt;code&gt;or&lt;/code&gt;  连接条件。&lt;/li&gt;
&lt;li&gt;索引方面：对要查询的条件的列， &lt;code&gt;order by&lt;/code&gt;  的字段建立索引，不要建立过多的索引，尽量使用组合索引。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;怎么看执行计划，里面的字段是什么意思？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;用 &lt;code&gt;explain&lt;/code&gt;  命令，后面跟查询语句： &lt;code&gt;explain select name from student;&lt;/code&gt; 。里面的字段，记不清，但是看到了我知道它代表什么意思。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;id&lt;/code&gt; ：每个 &lt;code&gt;select&lt;/code&gt;  语句都会分配一个唯一 &lt;code&gt;id&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;select_type&lt;/code&gt; ：对应的查询类型，有 &lt;code&gt;simple&lt;/code&gt; 、 &lt;code&gt;union&lt;/code&gt; 、 &lt;code&gt;primary&lt;/code&gt;  等&lt;/li&gt;
&lt;li&gt;&lt;code&gt;table&lt;/code&gt; ：表名&lt;/li&gt;
&lt;li&gt;&lt;code&gt;partitions&lt;/code&gt; ：匹配的分区信息&lt;/li&gt;
&lt;li&gt;&lt;code&gt;type&lt;/code&gt; ：表示这个查询对表执行查询时的访问方法，如 &lt;code&gt;const&lt;/code&gt; 、 &lt;code&gt;ref&lt;/code&gt; 、 &lt;code&gt;eq_ref&lt;/code&gt;  等。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;possible_key&lt;/code&gt; ：表示这个查询可能用到的索引&lt;/li&gt;
&lt;li&gt;&lt;code&gt;key&lt;/code&gt; ：实际用到的索引&lt;/li&gt;
&lt;li&gt;&lt;code&gt;key_len&lt;/code&gt; ：索引中形成的扫描区间和边界条件的列的长度&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ref&lt;/code&gt; ：与索引列进行等值匹配的是什么， &lt;code&gt;const&lt;/code&gt;  表示常数， &lt;code&gt;func&lt;/code&gt;  表示函数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rows&lt;/code&gt; ：表示查询的估计行数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filtered&lt;/code&gt; ：查询优化器预测扇出记录有多少条记录符合其余条件的百分比。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;extra&lt;/code&gt; ：记录一些额外信息，能够更准确理解 &lt;code&gt;MySQL&lt;/code&gt;  如何执行给定查询语句。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么不用 B 树而是用 B + 树？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;B + 树是 B 树的一种优化，B + 树非叶子节点存储的不是数据记录，而是目录记录。因为不存储数据，所以可以存储更多的目录记录，对应的叶子节点就可以存储更多的数据记录，使得整棵树层数更小，一般来说，一棵树都不会超过 4 层，所以查找起来非常快。其次在于所有记录在叶子节点，叶子节点的页连成双向链表，用于做范围查询有天然优势，而 B 树就很难做到。&lt;/p&gt;
&lt;p&gt;个人还有个浅显的理解，在增删记录时，B + 树一般修改的只有非叶子节点，以删除一条记录为例，如果删除的记录是该页中键值大小在中间的记录，那么直接删了就行，并不会影响上面的目录记录。但是如果是 B 树，删除的记录在往往会影响下面节点的记录的位置。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;什么是最左前缀原则和最左匹配原则？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;最左前缀：创建多列索引（组合索引），应该把 &lt;code&gt;where&lt;/code&gt;  使用最频繁的列放在索引的最左边。&lt;/li&gt;
&lt;li&gt;最左匹配：创建的组合索引 &lt;code&gt;(a,b,c)&lt;/code&gt;  相当于创建了索引 &lt;code&gt;(a)、(a,b)、(a,b,c)&lt;/code&gt;  三个索引。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;索引下推是什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;MySQL5.6&lt;/code&gt;  默认开启的索引下推，在联合索引中，比如是 &lt;code&gt;(a,b)&lt;/code&gt;  两个字段，再加上主键。假设有一条 &lt;code&gt;sql&lt;/code&gt;  语句的过滤条件涉及到 a、b 两个，那么索引下推开启后，存储引擎先找到所有符合关于 a 条件的数据，再根据索引中已经存在的 b 进行过滤。找到符合条件的数据，最后在回表查询。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvODdxc3JqLV9oRzU0dXhjT2xGcjM1UQ==&#34;&gt;https://mp.weixin.qq.com/s/87qsrj-_hG54uxcOlFr35Q&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;MySQL&lt;/code&gt;  调优你一般从哪些方面入手？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;查询 &lt;code&gt;explain&lt;/code&gt;  执行计划&lt;/li&gt;
&lt;li&gt;索引的建立一定要合适，尽量使索引满足最左前缀原则，查询过程中尽量触发索引覆盖和索引下推。&lt;/li&gt;
&lt;li&gt;在读多写少的业务场景中，建立普通索引使用 &lt;code&gt;change buffer&lt;/code&gt;  减少 IO 耗时。唯一索引并不能走 &lt;code&gt;change buffer&lt;/code&gt; ，因为更新操作需要判断是否违反唯一性约束。&lt;/li&gt;
&lt;li&gt;如果遇到很长的字段做索引，如何优化：
&lt;ul&gt;
&lt;li&gt;可以建立前缀索引，但是这可能会影响索引的选择性，需要根据实际情况来测试和调整&lt;/li&gt;
&lt;li&gt;建立哈希索引，将字段值映射到哈希值，再用哈希值做索引，但是这种不支持范围查询，只能精准查询。&lt;/li&gt;
&lt;li&gt;删除重复部分，考虑使不同字符之间区分度变高，如反转一下。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;像 &lt;code&gt;name like %xxx%&lt;/code&gt;  这种怎么优化？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看一下所有的查询条件，尽量将这种模糊匹配放到最后面，然后创建联合索引，多利用索引下推和索引覆盖。如果要查询的字段比较少，也可以建立联合索引，触发索引覆盖，因为二级索引的磁盘 IO 始终要少一些。&lt;/p&gt;
&lt;p&gt;还可以建立全文索引（但是准确度会有损失），对于只有前面有 &lt;code&gt;%&lt;/code&gt;  的模糊查询，看可以通过生成列 + 反转匹配规则来优化。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MveWd2dVAzNUJfc0pBbEJIdXVFSmhmZw==&#34;&gt;https://mp.weixin.qq.com/s/ygvuP35B_sJAlBHuuEJhfg&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;count(*)&lt;/code&gt;  和 &lt;code&gt;count(1)&lt;/code&gt;  的性能谁更好？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;count&lt;/code&gt;  函数本质为：在 &lt;code&gt;server&lt;/code&gt;  层维护一个 &lt;code&gt;count&lt;/code&gt; ，然后存储引擎查到一条记录返回，判断 &lt;code&gt;count&lt;/code&gt;  指定字段在记录里是否为 &lt;code&gt;NULL&lt;/code&gt; ，不为 &lt;code&gt;NULL&lt;/code&gt;  就 + 1。比如 &lt;code&gt;count(name)&lt;/code&gt;  就要对返回的记录查询是否 &lt;code&gt;name&lt;/code&gt;  为 &lt;code&gt;NULL&lt;/code&gt; 。但是 &lt;code&gt;count(1)&lt;/code&gt;  和 &lt;code&gt;count(*)&lt;/code&gt;  其实都没啥区别，执行计划应该都是一样的，因为 1 和 * 都不是 &lt;code&gt;NULL&lt;/code&gt; ，只要返回一条记录， &lt;code&gt;count&lt;/code&gt;  直接 ++ 即可。&lt;/p&gt;
&lt;p&gt;拓展一下： &lt;code&gt;count(主键)&lt;/code&gt;  和 &lt;code&gt;count(字段)&lt;/code&gt;  的效率反而更低一些，server 会读取返回的记录判断字段是否为 &lt;code&gt;NULL&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;如果有二级索引的话，执行计划更愿意走二级索引，因为二级索引更小，花费的磁盘 IO 也更小。&lt;/p&gt;
&lt;p&gt;如果一个表会很大，又想频繁执行 &lt;code&gt;count(*)&lt;/code&gt; ，优化方面可以取近似值（通过 &lt;code&gt;explain&lt;/code&gt;  查看估计的 &lt;code&gt;row&lt;/code&gt; ，如果精确度要求不高的话），还可以专门维护一张计数表。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;谈谈 &lt;code&gt;Buffer Pool&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了缓存&lt;strong&gt;磁盘&lt;/strong&gt;中的页，申请一片&lt;strong&gt;连续&lt;/strong&gt;内存，叫做 &lt;code&gt;Buffer Pool&lt;/code&gt; ，缓冲池的页与磁盘中的页一一对应。&lt;/p&gt;
&lt;p&gt;页与控制块为一对，控制块（保存页的表空间号，页号，在缓冲池中地址，链表节点等）在缓冲池前面，页在后面，向内占用内存，直到用完或者产生内存碎片。判断一个页是否已经被加载到缓存中，MySQL 使用的是哈希表，&lt;strong&gt;key&lt;/strong&gt; 为表空间号 + 页号，&lt;strong&gt;value&lt;/strong&gt; 为控制块。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Free 链表&lt;/strong&gt;：该链表上的页都是空闲的，还没被使用（修改）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flush 链表&lt;/strong&gt;：该链表上的页都是脏页，要实现持久化需要刷脏&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LRU 链表&lt;/strong&gt;：last recently used 链表，当缓冲池内存不够时，需要把那些不常使用的页回收重新分配。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;链表里面的节点都是控制块。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;最简单的 LRU 链表：页被访问，该页就会被放到 LRU 链表最前面。回收时，直接把链表尾部的页回收。但是 InnoDB 可以预读，会导致问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线性预读：顺序访问某个区的页超过某个值，就会将下个区的所有页都读到缓冲池中&lt;/li&gt;
&lt;li&gt;随机预读：一个区 13 个连续的页面都被加载到缓冲区中，该区所有的页面都会被加载到缓冲区&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这就导致可能根本用不到的页跑到链表前面，把常用的节点挤掉，降低 &lt;code&gt;Buffer Pool&lt;/code&gt;  命中率。&lt;/p&gt;
&lt;p&gt;同时，全表扫描也会导致这种问题，因为访问的页实在太多了，而且很多页都是因为要全表扫描而用几次就不用了。总结就是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加载的页可能用不到&lt;/li&gt;
&lt;li&gt;加载太多页导致常用的页被挤掉&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;只要访问一次页，就要导致链表节点变动，开销太大&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分区的 LRU 链表：把链表前部分设为 young 区域，存储使用频率非常高的页，也叫做&lt;strong&gt;热数据&lt;/strong&gt;。后部分设为 old 区域，存储使用频率不是很高的页，又叫做冷数据。同时一个页在一定时间间隔内被连续访问，就加载到 old 区，因为一个页有很多条记录，全表扫描在扫描一个页时会间隔很短的访问很多次。 还有一点：为了避免频繁的节点移动，只有被访问的缓冲页位于 young 区域 1/4 后面才会被移动到头部。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;刷脏：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从 LRU 链表的冷数据中刷新一部分到磁盘中&lt;/li&gt;
&lt;li&gt;从 flush 链表中刷新一部分到磁盘中&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;LRU 尾部的节点很容易被释放用于加载其他的页，在此之前，需要判断该页是否被修改，如果修改了，还需要先刷脏才行，这样其实是很慢的，而这种只刷新一个页面的操作叫做：&lt;strong&gt;BUF_FLUSH_SINGLE_PAGE&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其他&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;操作链表肯定是要上锁的，所以缓冲池可以被分为很多个 Buff Pool 实例，每个缓冲池实例维护各自的链表，提高并发量。&lt;/li&gt;
&lt;li&gt;5.7.5 之后，有了 Chunk 这个概念，表示一片连续内存的单位，Buff Pool 就是由若干个 Chunk 组成。一个 Chunk 包含了若干个页 + 控制块。所以服务器运行时就可以通过增删 Chunk 来改变缓冲池大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;事物的隔离级别有哪些？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;SQL&lt;/code&gt;  标准定义的隔离级别有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读未提交：可以读到其他未提交事务修改的数据，也会导致脏读、不可重复读、幻读。&lt;/li&gt;
&lt;li&gt;读提交：可以读到其他事务提交后的数据，会导致不可重复读、幻读。&lt;/li&gt;
&lt;li&gt;可重复读：先读 A，A 被其他事务修改然后提交后，再读 A 还是原来的数据。保证一个事务中同一个数据的一致性，会导致幻读（&lt;strong&gt;t1 查询，t2 插入并提交，t1 修改后可以查到，这就导致幻读&lt;/strong&gt;）。&lt;/li&gt;
&lt;li&gt;串行化：性能最差，最安全。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;redo log&lt;/code&gt;  的持久化策略&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;redo&lt;/code&gt;  日志的持久化策略有几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;后台每秒一次，将 &lt;code&gt;redo log buffer&lt;/code&gt;  持久化到磁盘&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MySQL&lt;/code&gt;  正常关闭时&lt;/li&gt;
&lt;li&gt;当 &lt;code&gt;redo&lt;/code&gt;  日志大小超过 &lt;code&gt;redo log buffer&lt;/code&gt;  大小一般时，就会持久化到磁盘中&lt;/li&gt;
&lt;li&gt;每次&lt;strong&gt;事务提交时&lt;/strong&gt;，根据 &lt;code&gt;commit&lt;/code&gt;  参数决定何时持久化到磁盘中。如果为 0，不会主动触发写入磁盘；如果为 1，主动持久化到磁盘；如果为 2，每次事务提交会写入 &lt;code&gt;redo log&lt;/code&gt;  文件，本质上时写入 &lt;code&gt;Page Cache&lt;/code&gt;  而不是写入磁盘。对于 2 而言， &lt;code&gt;MySQL&lt;/code&gt;  崩了，但是只要操作系统不崩，数据也会从 &lt;code&gt;page cache&lt;/code&gt;  写入到磁盘中。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;redo log&lt;/code&gt;  的存储是怎样的？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;redo&lt;/code&gt;  日志存储到文件中并使用循环存储，如果所有文件满了就会从头覆盖存储，覆盖是有条件的，如果不符合条件导致无法覆盖， &lt;code&gt;MySQL&lt;/code&gt;  就会拒绝更新操作，从而阻塞。&lt;/p&gt;
&lt;p&gt;一个 &lt;code&gt;redo&lt;/code&gt;  日志能否覆盖，取决于 &lt;code&gt;lsn&lt;/code&gt;  值，它是该条 &lt;code&gt;redo&lt;/code&gt;  日志的偏移量。关于 lsn 记录，每次一组 redo 日志写入时都会记录 lsn，同时缓冲池中的 flush 链表中每个页的控制块都记录了两个变量 old_lsn 和 new_lsn。前者是页第一次被修改时记录的 lsn（flush 链表节点其实是按照 old_lsn 进行排序的，尾节点的 old_lsn 最小。应该有某种机制，保证并发环境下，小的 lsn 比大的 lsn 加载的页面先进入 flush 链表），后者是最近一次修改时记录的 lsn。当刷脏时，会将 flush 尾节点先刷磁盘，假设这个尾节点的 old_lsn 为&lt;strong&gt; A&lt;/strong&gt;，那么 redo 日志文件组中 &lt;code&gt;lsn&amp;lt;A&lt;/code&gt;  的日志都会失效。当一个页刷脏后，磁盘中页的 header 会记录下此时的 &lt;code&gt;new_lsn&lt;/code&gt; ，当通过 redo 日志恢复时，如果关于某个页的 redo 日志的 &lt;code&gt;lsn&amp;lt;new_lsn&lt;/code&gt; ，也不用进行，直接跳过，加快速度。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;binlog&lt;/code&gt;  和 &lt;code&gt;redo log&lt;/code&gt;  的区别？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;适用对象不同： &lt;code&gt;binlog&lt;/code&gt;  产生于 &lt;code&gt;server&lt;/code&gt;  层，而 &lt;code&gt;redo log&lt;/code&gt;  是 &lt;code&gt;InnoDB&lt;/code&gt;  产生的&lt;/li&gt;
&lt;li&gt;文件格式不同： &lt;code&gt;redo log&lt;/code&gt;  有专门的压缩，文件比较小； &lt;code&gt;binlog&lt;/code&gt;  的文件格式比较多，有 &lt;code&gt;STATEMENT&lt;/code&gt; 、 &lt;code&gt;ROW&lt;/code&gt; 、 &lt;code&gt;MIXED&lt;/code&gt;  三种。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;STATEMENT&lt;/code&gt; ：只记录命令，这种缺点就是如果命令中使用了一些动态函数，比如 &lt;code&gt;uuid&lt;/code&gt; 、 &lt;code&gt;now&lt;/code&gt;  之类的，主从数据库可能出现不一致。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ROW&lt;/code&gt; ：记录行记录被改变后的结果，改动多少行就记录多少行，有时 &lt;code&gt;binlog&lt;/code&gt;  文件会因为一条命令变得很大&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MIXED&lt;/code&gt; ：包含了前两种模式，会根据不同的情况自动使用 &lt;code&gt;STATEMENT&lt;/code&gt;  和 &lt;code&gt;ROW&lt;/code&gt;  模式。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;写入方式不同： &lt;code&gt;binlog&lt;/code&gt;  是追加， &lt;code&gt;redo log&lt;/code&gt;  是循环写，文件大小是固定的。&lt;/li&gt;
&lt;li&gt;用途不同： &lt;code&gt;binlog&lt;/code&gt;  用于备份恢复，主从复制； &lt;code&gt;redo log&lt;/code&gt;  用于断电等故障恢复。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;binlog&lt;/code&gt;  也能恢复数据，为什么还要 &lt;code&gt;redo log&lt;/code&gt; ?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这是 &lt;code&gt;MySQL&lt;/code&gt;  发展原因， &lt;code&gt;InnoDB&lt;/code&gt;  不是一开始就有的， &lt;code&gt;MySQL&lt;/code&gt;  默认得存储引擎是 &lt;code&gt;MyISAM&lt;/code&gt; ，而此时就已经有 &lt;code&gt;binlog&lt;/code&gt;  了，所以设计 &lt;code&gt;binlog&lt;/code&gt;  时一开始也没有设计恢复数据页能力和一些必要的功能。 &lt;code&gt;InnoDB&lt;/code&gt;  出来后可以支持事务，所以需要 &lt;code&gt;redo log&lt;/code&gt; ， &lt;code&gt;binlog&lt;/code&gt;  在恢复事务方面并没有 &lt;code&gt;redo log&lt;/code&gt;  那样好， &lt;code&gt;redo log&lt;/code&gt;  不仅需要记录事务导致哪些页发生变化，还要记录 &lt;code&gt;undo log&lt;/code&gt;  变化的页，还要考虑日志刷脏问题。&lt;/p&gt;
&lt;p&gt;而且 &lt;code&gt;redo log&lt;/code&gt;  的出现，通过两阶段提交，保证了数据的完整：sql 更新操作将数据更新到内存，并且记录到 &lt;code&gt;redo log&lt;/code&gt;  中，此时 &lt;code&gt;redo log&lt;/code&gt;  处于 &lt;code&gt;prepare&lt;/code&gt;  状态，执行器生成该操作的 &lt;code&gt;binlog&lt;/code&gt;  并写入磁盘，此时 &lt;code&gt;redo log&lt;/code&gt;  的状态才改为 &lt;code&gt;commit&lt;/code&gt;  状态，完成更新。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;看你简历写了熟悉 &lt;code&gt;MVCC&lt;/code&gt; ，能说说是什么原理吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;解释 &lt;code&gt;MVCC&lt;/code&gt;  首先要回到事务隔离级别以及如何实现这种隔离级别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;读未提交&lt;/strong&gt;是事务可以读到其他事务修改但未提交的数据，会造成脏读，这种隔离级别实现直接读最新的数据即可。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;读提交&lt;/strong&gt;是事务可以读到其他事务修改并提交后的数据，&lt;strong&gt;可重复读&lt;/strong&gt;是连其他事务修改了的数据都不能读，这两者就是通过 &lt;code&gt;MVCC&lt;/code&gt;  实现的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;串行化&lt;/strong&gt;直接加锁即可，性能最低，但最安全。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以平时业务需要根据对数据一致性的不同要求设置不同的事务隔离。提到 &lt;code&gt;MVCC&lt;/code&gt; ，是基于 &lt;code&gt;undo&lt;/code&gt;  日志形成的版本链和 &lt;code&gt;ReadView&lt;/code&gt;  实现的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;版本链&lt;/strong&gt;：每条记录都有一个隐藏属性 &lt;code&gt;roll_pointer&lt;/code&gt;  可以指向上一个记录的版本，这个版本实质上就是 &lt;code&gt;undo&lt;/code&gt;  日志，而 &lt;code&gt;undo&lt;/code&gt;  日志本身也是记录，也有 &lt;code&gt;roll_pointer&lt;/code&gt; ，从而就形成了版本链。还需要提到的就是，记录还有一个隐藏属性 &lt;code&gt;trx_id&lt;/code&gt; ，表示该记录版本的事务 &lt;code&gt;id&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ReadView&lt;/strong&gt;：产生的时机待会再说，器中包括了几个重要的属性
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;m_ids&lt;/code&gt; ：生成 &lt;code&gt;ReadView&lt;/code&gt;  时，还在活跃的所有事务的 &lt;code&gt;id&lt;/code&gt; ，活跃就是指还没有提交的事务。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min_trx_id&lt;/code&gt; ：生成 &lt;code&gt;ReadView&lt;/code&gt;  时，还在活跃的最小的事务 &lt;code&gt;id&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_trx_id&lt;/code&gt; ：生成 &lt;code&gt;ReadView&lt;/code&gt;  时，下一个事务应该被分配的 &lt;code&gt;id&lt;/code&gt; 。注意它并不是 &lt;code&gt;m_ids&lt;/code&gt;  中的最大值。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;creator_trx_id&lt;/code&gt; ：创建该 &lt;code&gt;ReadView&lt;/code&gt;  的事务的 &lt;code&gt;id&lt;/code&gt; 。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们先看一下 &lt;code&gt;MVCC&lt;/code&gt;  如何实现&lt;strong&gt;读提交&lt;/strong&gt;的隔离性，这个级别的要求就是事务可以读到已提交的事务的修改。我们假设所有的事务都在对记录 A（此时 A 的 &lt;code&gt;trx_id&lt;/code&gt;  为 80，该事务已经提交）进行修改和读取。当事务 100 修改了两次记录 A，那么关于记录 A 的版本链 &lt;code&gt;100-&amp;gt;100-&amp;gt;80&lt;/code&gt; 。然后事务 90 要对记录 A 进行查询，此时就会响应 &lt;code&gt;select&lt;/code&gt;  生成 &lt;code&gt;ReadView&lt;/code&gt; ，那么这个 &lt;code&gt;ReadView&lt;/code&gt;  的 &lt;code&gt;m_ids&lt;/code&gt;  就包括了 100，然后先读到第一个 100，发现 100 已经在 &lt;code&gt;m_ids&lt;/code&gt;  中，表示这个事务还没有提交，就不能读到它的修改的数据，就向下查找，直到找到 80 这个版本，发现已经提交了，可以读。&lt;/p&gt;
&lt;p&gt;后来假设事务 100 已经提交了，那么事务 90 再执行查询语句，又会新生成一个 &lt;code&gt;ReadView&lt;/code&gt; ，此时 &lt;code&gt;m_ids&lt;/code&gt;  就不会包含 100 了，也就可以读到 100 的记录版本了。&lt;/p&gt;
&lt;p&gt;再看一下如何实现&lt;strong&gt;可重复读&lt;/strong&gt;的隔离级别，它要保证整个事务的数据都是一致的，其实对应的策略就是只生成一个 &lt;code&gt;ReadView&lt;/code&gt; ，而不是每次查询都生成一个 &lt;code&gt;ReadView&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;参考：《MySQL 是怎样运行的》第 21 章，作者 —— 小孩子 4919&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://cecilia.cool/2023/03/08/%E5%85%AB%E8%82%A1%E6%96%87/Redis/</guid>
            <title>Redis</title>
            <link>https://cecilia.cool/2023/03/08/%E5%85%AB%E8%82%A1%E6%96%87/Redis/</link>
            <category>八股文</category>
            <pubDate>Wed, 08 Mar 2023 17:27:22 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;本文积累了我在（准备）面试的关于 &lt;code&gt;Redis&lt;/code&gt;  的问题，当然我不喜欢背八股文，所以就会强迫自己去系统性学习， &lt;code&gt;Redis&lt;/code&gt;  之前我开了一个 &lt;code&gt;tag&lt;/code&gt;  的，但是没更完就要准备面试了，Java 后端岗位太卷了！！&lt;/p&gt;
&lt;p&gt;大部分参考&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly94aWFvbGluY29kaW5nLmNvbS8=&#34;&gt;小林 Coding&lt;/span&gt; 以及敖丙的&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9naXRodWIuY29tL0FvYmluZ0phdmEvSmF2YUZhbWlseQ==&#34;&gt; JavaFamily&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;通用篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#通用篇&#34;&gt;#&lt;/a&gt; 通用篇&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  为什么这么快？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有几个方面的原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单线程执行，在 6.0 版本以前处理网络请求和数据操作都是单线程，减少了上下文切换，性能对于一些中小项目是完全足够的。网络请求处理使用的 IO 多路复用，数据处理因为是在内存中操作，CPU 资源并不会限制 &lt;code&gt;Redis&lt;/code&gt;  性能。6.0 版本对网络处理使用了多线程，保留数据操作使用单线程，同时页保证不会出现并发问题。&lt;/li&gt;
&lt;li&gt;基于内存操作，不必多说，比 &lt;code&gt;MySQL&lt;/code&gt;  要请求磁盘快多了。&lt;/li&gt;
&lt;li&gt;高效的数据结构， &lt;code&gt;Redis&lt;/code&gt;  底层使用了很多高效的数据结构，比如 &lt;code&gt;SDS&lt;/code&gt; 、压缩列表、跳表、哈希表等。&lt;/li&gt;
&lt;li&gt;自定义协议：使用了高性能的自定义 &lt;code&gt;Redis&lt;/code&gt;  协议 RESP 和协议分析器。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些因素加起来使得 &lt;code&gt;Redis&lt;/code&gt;  能够达到一秒十万级别的处理。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvS3R6dmF3RG5RUXdoZmpuQ29YcGNNUQ==&#34;&gt;https://mp.weixin.qq.com/s/KtzvawDnQQwhfjnCoXpcMQ&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvbXNjS0luV05BdWhDYmcxODNVbTlfZw==&#34;&gt;https://mp.weixin.qq.com/s/mscKInWNAuhCbg183Um9_g&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;数据类型篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#数据类型篇&#34;&gt;#&lt;/a&gt; 数据类型篇&lt;/h1&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s3.bmp.ovh/imgs/2023/04/11/2f2235362ca92700.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;String、List、Hash、Set、Zset、Stream、Hyperloglog、GEO、BitMap、BloomFilter&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;redisObject&lt;/code&gt;  是什么，为什么需要这个对象？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;redis&lt;/code&gt;  是键值数据库，这意味着会对键有大量的操作，一些命令只适用于特定的数据类型，如 &lt;code&gt;zadd&lt;/code&gt;  只适用于 &lt;code&gt;zset&lt;/code&gt;  而不适合 &lt;code&gt;string&lt;/code&gt; ，但是又有一些命令适用于所有 &lt;code&gt;key&lt;/code&gt; ，如 &lt;code&gt;ttl&lt;/code&gt; 、 &lt;code&gt;del&lt;/code&gt;  等，所以这些命令要正确执行， &lt;code&gt;key&lt;/code&gt;  就需要带有类型信息，使得程序可以检查 &lt;code&gt;key&lt;/code&gt;  类型，选择合适的处理方式。&lt;/p&gt;
&lt;p&gt;为此 &lt;code&gt;redis&lt;/code&gt;  构建了自己的类型系统，包括显示多态，类型判断，对象分配销毁和共享。 &lt;code&gt;redisObject&lt;/code&gt;  的属性有 &lt;code&gt;type、encoding、lru、refcount、ptr&lt;/code&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight c&#34;&gt;&lt;figcaption data-lang=&#34;c&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;typedef&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;redisObject&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token comment&#34;&gt;// 类型，判断数据类型&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;unsigned&lt;/span&gt; type&lt;span class=&#34;token operator&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;6&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token comment&#34;&gt;// 编码方式，判断数据结构&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;7&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;unsigned&lt;/span&gt; encoding&lt;span class=&#34;token operator&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;8&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;9&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token comment&#34;&gt;// LRU - 24 位，记录最末一次访问时间（相对于 lru_clock）; 或者 LFU（最少使用的数据：8 位频率，16 位访问时间）&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;10&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;unsigned&lt;/span&gt; lru&lt;span class=&#34;token operator&#34;&gt;:&lt;/span&gt;LRU_BITS&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;token comment&#34;&gt;// LRU_BITS: 24&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;11&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;12&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token comment&#34;&gt;// 引用计数&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;13&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;int&lt;/span&gt; refcount&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;14&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;15&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token comment&#34;&gt;// 指向底层数据结构实例&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;16&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;*&lt;/span&gt;ptr&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;17&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;18&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt; robj&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;当执行一个命令时，假设是 &lt;code&gt;zadd&lt;/code&gt; ，就会先将 &lt;code&gt;key&lt;/code&gt;  从字典中找到对应的 &lt;code&gt;redisObject&lt;/code&gt; ，如果为 &lt;code&gt;null&lt;/code&gt;  就说明 &lt;code&gt;key&lt;/code&gt;  不存在，然后继续检查 &lt;code&gt;type&lt;/code&gt;  是否正确，最后根据 &lt;code&gt;encoding&lt;/code&gt;  判断底层的数据结构到底是什么来调用多态函数。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9wZGFpLnRlY2gvbWQvZGIvbm9zcWwtcmVkaXMvZGItcmVkaXMteC1yZWRpcy1vYmplY3QuaHRtbA==&#34;&gt;https://pdai.tech/md/db/nosql-redis/db-redis-x-redis-object.html&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cubW9kYi5wcm8vZGIvNzI5NDc=&#34;&gt;https://www.modb.pro/db/72947&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Redis 的 &lt;code&gt;SDS&lt;/code&gt;  是什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;脑图：回忆一下当初学 C 语言时字符串的缺陷， &lt;code&gt;SDS&lt;/code&gt;  就是为了克服这些缺陷。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SDS&lt;/code&gt;  是 &lt;code&gt;Redis&lt;/code&gt;  自定义的简单动态字符串，也是 &lt;code&gt;Redis&lt;/code&gt;  最基本的数据结构之一。设计 &lt;code&gt;SDS&lt;/code&gt;  是因为 c 语言的字符串问题太多，性能太低了。主要问题是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;获取长度时间复杂度为 &lt;code&gt;O(N)&lt;/code&gt; ， &lt;code&gt;SDS&lt;/code&gt;  内部维护了当前字符串长度 &lt;code&gt;len&lt;/code&gt; ， &lt;code&gt;O(1)&lt;/code&gt;  复杂度&lt;/li&gt;
&lt;li&gt;操作不方便，容易溢出，类似 &lt;code&gt;strcat&lt;/code&gt;  这种函数，拼接两个字符串，都会默认前一个字符串剩余空间足够，所以很不方便。 &lt;code&gt;SDS&lt;/code&gt;  维护了当前分配空间大小 &lt;code&gt;alloc&lt;/code&gt; ，可以检测剩余空间。&lt;/li&gt;
&lt;li&gt;以 &lt;code&gt;\0&lt;/code&gt;  结束，需要指定编码格式。这种性质使得字符串只能存储文本文件， &lt;code&gt;SDS&lt;/code&gt;  使用了字节数组，使得可以存储任何可转为字节的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;SDS&lt;/code&gt;  还可以动态扩容，并且会还会多分配一些未使用空间，减少分配次数。具体是，当操作触发扩容机制，会先算出需要扩容到多少才够，这个值保存在 &lt;code&gt;newLen&lt;/code&gt;  中，然后真正扩容还会多分配一些空间：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果 &lt;code&gt;newLen &amp;lt; 1MB&lt;/code&gt; ，那么 &lt;code&gt;newLen *= 2&lt;/code&gt;  再进行扩容&lt;/li&gt;
&lt;li&gt;如果 &lt;code&gt;newLen &amp;gt;= 1MB&lt;/code&gt; ，那么 &lt;code&gt;newLen += 1MB&lt;/code&gt;  再进行扩容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;SDS&lt;/code&gt;  设计了不同类型的结构体，区别在于 &lt;code&gt;len&lt;/code&gt;  和 &lt;code&gt;alloc&lt;/code&gt;  的大小不同，通过为不同大小字符串灵活分配，可以节省内存。&lt;/p&gt;
&lt;figure class=&#34;highlight c&#34;&gt;&lt;figcaption data-lang=&#34;c&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;__attribute__&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;__packed__&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;sdshdr16&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token class-name&#34;&gt;uint16_t&lt;/span&gt; len&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token class-name&#34;&gt;uint16_t&lt;/span&gt; alloc&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; &lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;char&lt;/span&gt; flags&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; 	&lt;span class=&#34;token comment&#34;&gt;// SDS 类型&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;char&lt;/span&gt; buf&lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;6&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;最后， &lt;code&gt;SDS&lt;/code&gt;  还使用了编译优化 &lt;code&gt;__attribute__ ((__packed__))&lt;/code&gt; ，告诉编译器取消结构在编译中的对齐优化，而是实际使用多少就分配多少。比如一个结构体有 1 个 &lt;code&gt;int&lt;/code&gt;  和 1 个 &lt;code&gt;char&lt;/code&gt; ，正常的优化对齐会使 &lt;code&gt;char&lt;/code&gt;  对齐 &lt;code&gt;int&lt;/code&gt; ，也就是 &lt;code&gt;char&lt;/code&gt;  也会占 3 个字节。其实这 3 个字节就浪费了。 &lt;code&gt;SDS&lt;/code&gt;  的编译优化就可以使 &lt;code&gt;char&lt;/code&gt;  只分配一个字节。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SDS&lt;/code&gt;  与 &lt;code&gt;redisObject&lt;/code&gt;  的关系根据字符串存储的值的不同而有所不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;字符串对象保存的整数值，并且该整数可以用 &lt;code&gt;long&lt;/code&gt;  表示，那么就会把 &lt;code&gt;redisObject.ptr&lt;/code&gt;  从 &lt;code&gt;void*&lt;/code&gt;  改为 &lt;code&gt;long&lt;/code&gt; ，并设置 &lt;code&gt;encoding=int&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;字符串对象保存的字符串，则使用 &lt;code&gt;SDS&lt;/code&gt;  保存字符串， &lt;code&gt;ptr&lt;/code&gt;  指向 &lt;code&gt;SDS&lt;/code&gt;  地址，实际数据放在 &lt;code&gt;SDS&lt;/code&gt;  中的 &lt;code&gt;buf&lt;/code&gt;  中。如果字符串字节长度 &lt;code&gt;&amp;lt;=X&lt;/code&gt; ，则 &lt;code&gt;encoding=embstr&lt;/code&gt;  反之则 &lt;code&gt;encoding=raw&lt;/code&gt; 。（x 在个版本中定义不同，2.+ 是 32，3.0-4.0 是 39，5.0 是 44）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;embstr&lt;/code&gt;  会一次性分配 &lt;code&gt;redisObject&lt;/code&gt;  和 &lt;code&gt;SDS&lt;/code&gt;  的空间，有利于内存连续更好利用 CPU 缓存，减少内存分配次数，内存释放次数。而 &lt;code&gt;raw&lt;/code&gt;  就需要分配两次。 &lt;code&gt;embstr&lt;/code&gt;  是只读的，如果要对 &lt;code&gt;embstr&lt;/code&gt;  操作，就会先升级为 &lt;code&gt;raw&lt;/code&gt;  再执行修改命令。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvcXB0RTE3MnNsZ182VGwxeXV6ZGJmdw==&#34;&gt;https://mp.weixin.qq.com/s/qptE172slg_6Tl1yuzdbfw&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;redis&lt;/code&gt;  的 &lt;code&gt;BitMap&lt;/code&gt;  是什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;位图，本质就是比特数组，用于存储一些只有两个状态的数据，占用空间小，实际应用：打卡，判断用户登录态（5000 万用户只需要 6MB 空间）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;刚才你提到了 &lt;code&gt;HyperLoglog&lt;/code&gt; ，知道什么原理吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;HyperLoglog&lt;/code&gt;  是一个基于基数统计（集合中不重复元素的个数）的数据结构（12kB 就可以统计 2^64 的数据量），其实底层算法很早之前就有人提出了，但是 &lt;code&gt;Redis&lt;/code&gt;  第一次使用数据结构将其实现。说到应用，我们可以假设一个场景，有个业务需求需要每个网页都统计访问量，同一 IP 多次访问只算做一次访问。如果是在业务端实现，最先想到的就是对每一个网页加一个 &lt;code&gt;Set&lt;/code&gt; ，最后需要统计量时直接获取集合大小即可，如果访问量很大，上百万、千万什么的，就非常消耗内存，不可能为了这么小的业务需求付出这么大的内存，并且这种业务是可以容忍一定误差的，所以就可以使用 &lt;code&gt;Redis&lt;/code&gt;  里的 &lt;code&gt;HyperLoglog&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;至于原理，涉及到统计概率中的伯努利实验，以及后来者引入的桶和加权平均等修正，我还没来得及深入了解。仅仅只知道这确实可以统计去重元素个数，但是存在一点误差，如果可以容忍误差，那么性能是很高的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;GEO&lt;/code&gt;  是什么，有什么用？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;GEO&lt;/code&gt;  并没有设计新的数据结构，而是使用了 &lt;code&gt;Sorted Set&lt;/code&gt; ，使用 &lt;code&gt;GeoHash&lt;/code&gt;  编码方法实现了经纬度到元素权重分数的转换，关键就是【对二维地图做区间划分】和【对区间进行编码】，经纬度落到某个区间，就用这个区间的编码值表示 &lt;code&gt;Sorted Set&lt;/code&gt;  元素的权重分数。&lt;/p&gt;
&lt;p&gt;实际应用如&lt;strong&gt;滴滴叫车&lt;/strong&gt;：主要使用 &lt;code&gt;GEOADD&lt;/code&gt;  和 &lt;code&gt;GEORADIUS&lt;/code&gt;  两个命令。使用 &lt;code&gt;GEO&lt;/code&gt;  集合保存所有车辆的经纬度，当用户想寻找自己附近的车，LBS（Location Based Services）应用就可以以用户的经纬度为中心指定公里内的车辆信息找到并返回。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  的压缩列表了解过吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;压缩列表是 &lt;code&gt;Redis&lt;/code&gt;  的基础数据结构，如果 &lt;code&gt;list&lt;/code&gt;  或者 &lt;code&gt;hash&lt;/code&gt;  的节点较少，且保存的项都是一些小整数或者短字符串，通常会使用压缩列表来作为列表键的底层实现。&lt;/p&gt;
&lt;p&gt;压缩列表的本质是数组，不用链表是因为链表的节点之间内存不连续，无法高效利用 &lt;code&gt;CPU&lt;/code&gt;  缓存，命中率很低。而压缩列表是内存连续的，命中率高。&lt;/p&gt;
&lt;p&gt;压缩列表前面几个字段是列表的一些信息，比如列表占用字节数，列表尾部节点的偏移量，节点数量，压缩列表结束点。而每个节点的构成为：前一个节点的长度，自身数据类型和节点长度，数据。&lt;/p&gt;
&lt;p&gt;为了尽可能节省内存，和 &lt;code&gt;MySQL&lt;/code&gt;  记录中 &lt;code&gt;varchar&lt;/code&gt;  一样，使用了不同字节来记录数据长度。前一个节点长度在 256 之内，使用 1 个字节，反之使用 5 个字节。但是这种机制会导致&lt;strong&gt;连锁更新&lt;/strong&gt;问题，比如首节点插入长度大于 256 的数据，而下一个节点之前记录长度使用的 1 字节，此时就需要扩容，扩容后可能自身也超过了 256 字节，它的下一个节点也要扩容，如此往复，直到最后一个节点扩容完成。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvcXB0RTE3MnNsZ182VGwxeXV6ZGJmdw==&#34;&gt;https://mp.weixin.qq.com/s/qptE172slg_6Tl1yuzdbfw&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  的哈希表了解过吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;哈希表是 &lt;code&gt;Redis&lt;/code&gt;  的基础数据结构，数据类型 &lt;code&gt;hash&lt;/code&gt;  如果节点很多或者项是大的整数、长字符串，就会使用哈希表。哈希表底层实现使用的是数组，链式增长解决哈希冲突。当负载因子 &lt;code&gt;&amp;gt;= 1&lt;/code&gt;  时，如果没有执行 &lt;code&gt;rdb&lt;/code&gt;  或 &lt;code&gt;aof&lt;/code&gt;  就会 &lt;code&gt;rehash&lt;/code&gt; 。当负载因子 &lt;code&gt;&amp;gt;=5&lt;/code&gt;  时，不论有没有 &lt;code&gt;rdb\aof&lt;/code&gt;  都会 &lt;code&gt;rehash&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rehash&lt;/code&gt;  使用的是渐进式 &lt;code&gt;rehash&lt;/code&gt; ，假设原哈希表 1 扩容后为哈希表 2，那么在 &lt;code&gt;rehash&lt;/code&gt;  的过程中，每次有请求增删改查哈希表 1，就会把当前索引的节点转移到哈希表 2，使得整个 &lt;code&gt;rehash&lt;/code&gt;  过程分配到各个请求上，避免一次性 &lt;code&gt;rehash&lt;/code&gt;  的耗时操作。&lt;/p&gt;
&lt;p&gt;如果有一个查询请求，在哈希表 1 查不到，就会去哈希表 2 查询。在渐进式 &lt;code&gt;rehash&lt;/code&gt;  进行期间，哈希元素的操作都是在两个哈希表进行的。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvcXB0RTE3MnNsZ182VGwxeXV6ZGJmdw==&#34;&gt;https://mp.weixin.qq.com/s/qptE172slg_6Tl1yuzdbfw&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  的整数集合是什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;整数集合是实现 &lt;code&gt;set&lt;/code&gt;  的数据结构之一，底层其实就是整数数组&lt;/p&gt;
&lt;figure class=&#34;highlight c&#34;&gt;&lt;figcaption data-lang=&#34;c&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;typedef&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;intset&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token comment&#34;&gt;// 编码方式&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token class-name&#34;&gt;uint32_t&lt;/span&gt; encoding&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token comment&#34;&gt;// 集合包含的元素数量&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token class-name&#34;&gt;uint32_t&lt;/span&gt; length&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;6&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token comment&#34;&gt;// 保存元素的数组&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;7&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token class-name&#34;&gt;int8_t&lt;/span&gt; contents&lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;8&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt; intset&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;但是数组的元素类型由 &lt;code&gt;encoding&lt;/code&gt;  控制，从 &lt;code&gt;8bit&lt;/code&gt; 、 &lt;code&gt;16bit&lt;/code&gt; 、 &lt;code&gt;32bit&lt;/code&gt; 、 &lt;code&gt;64bit&lt;/code&gt;  增长。不一来就用 &lt;code&gt;64bit&lt;/code&gt;  也是想尽量节省空间。在插入新元素时，会维护有序性和唯一性。如果插入的整数所占用的字节超过了数组 1 个元素的字节，就要先升级再插入&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  的跳表了解过吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;跳表算是一种很优雅的实现，相较于普通链表，查询效率提升，相较于二叉树，省去了平衡、树退化的问题。比如一个链表节点为： &lt;code&gt;1 2 3 4 5 &lt;/code&gt; 那么从中挑出一半 &lt;code&gt;1 3 5&lt;/code&gt;  形成新的链表，并且将新的链表接到原来的链表上面，如此直到最上面的节点只有 1 个。这种数据结构使得查询效率为 &lt;code&gt;O(logn)&lt;/code&gt; 。但是当插入新节点时，需要调整上面的节点，严重时时间复杂度还是 &lt;code&gt;O(n)&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;所以 &lt;code&gt;Redis&lt;/code&gt;  也是优化了跳表，在每次插入节点时就通过随机数决定其层数（随机数 r&amp;lt;=0.25 就加一，继续生成，&amp;gt;0.25 就停止），然后提前加入到对应的层数。这样虽然不是严格的 &lt;code&gt;log2N&lt;/code&gt; ，也许要存储的节点会变多，也可能变小，但总的效率依然维持在一个很高的水平。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;Redis&lt;/code&gt;  常用的数据类型中， &lt;code&gt;zset&lt;/code&gt;  就是通过跳表实现的。&lt;/p&gt;
&lt;p&gt;至于为什么 &lt;code&gt;zset&lt;/code&gt;  使用了跳表而不是平衡树，原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平衡树实现复杂，还要考虑插入删除后树的平衡调整。&lt;/li&gt;
&lt;li&gt;在&lt;strong&gt;范围查找&lt;/strong&gt;时，平衡树比较难实现，而跳表只需要找到最小值然后遍历即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvTk9zWGRyTXJXd3E0TlRtMTgwYTZ2dw==&#34;&gt;https://mp.weixin.qq.com/s/NOsXdrMrWwq4NTm180a6vw&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;redis&lt;/code&gt;  的 &lt;code&gt;quicklist&lt;/code&gt;  了解过吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;3.0&lt;/code&gt;  版本之前，列表都是使用 &lt;code&gt;list&lt;/code&gt;  和压缩列表（ &lt;code&gt;ziplist&lt;/code&gt; ）实现的， &lt;code&gt;3.2&lt;/code&gt;  之后就是只使用 &lt;code&gt;quicklist&lt;/code&gt;  实现了。 &lt;code&gt;quicklist&lt;/code&gt;  其实就是 &lt;code&gt;list+ziplist&lt;/code&gt; 。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;redis&lt;/code&gt;  的 &lt;code&gt;listpack&lt;/code&gt;  了解过吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;listpack&lt;/code&gt;  也是一种压缩列表的实现，之前提到的 &lt;code&gt;quicklist&lt;/code&gt;  并没有解决连锁更新的问题，就是因为节点记录了前一个节点的长度，为了能后从后向前遍历，所以 &lt;code&gt;listpack&lt;/code&gt;  不再记录前一个节点的长度而是记录当前节点的长度。其实这也能从后向前遍历，是由 &lt;code&gt;lpDecodeBacklen&lt;/code&gt;  函数实现，它会从当前列表项起始位置的指针开始，向左逐个字节解析，得到前一项的  &lt;code&gt;entry-len&lt;/code&gt;  值。&lt;/p&gt;
&lt;h1 id=&#34;持久化篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#持久化篇&#34;&gt;#&lt;/a&gt; 持久化篇&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  如何保证数据持久化？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  为了保证数据高可用，引入了持久化机制， 在早期版本，还有 VM，后来版本不推荐了。现在一般都是使用 &lt;code&gt;RDB&lt;/code&gt; 、 &lt;code&gt;AOF&lt;/code&gt;  或者混合持久化。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;RDB&lt;/code&gt;  通过对内存数据拍摄快照来持久化数据，触发机制是在一定时间内发生一定次数的修改操作。当然也可以使用 &lt;code&gt;save/bgsave&lt;/code&gt;  主动拍摄快照，前者会阻塞线程，后者才会 &lt;code&gt;fork&lt;/code&gt;  一个子线程进行快照拍摄。因为采用了压缩算法，实际占用空间很小。异步存储为了保证数据一致性，借助了操作系统的 &lt;code&gt;Copy on Write&lt;/code&gt;  机制，主线程修改哪个页，就会先将这个页复制出来，复制页是用于 rdb，主进程还是在原地址修改。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;AOF&lt;/code&gt;  通过存储执行的命令到磁盘中保证数据的持久性，可以配置多种存储方式，比如&lt;strong&gt;执行一条命令就存储一条&lt;/strong&gt;，或者&lt;strong&gt;每秒存储一次&lt;/strong&gt;，或者&lt;strong&gt;看系统心情&lt;/strong&gt;，什么时候有空什么时候就将缓冲区的命令存进去。 &lt;code&gt;AOF&lt;/code&gt;  机制执行久了，就会导致文件保存了很多无效的命令，所以需要重写 &lt;code&gt;AOF&lt;/code&gt;  文件 —— &lt;code&gt;bgrewriteaof&lt;/code&gt; ，过程为：子线程遍历 &lt;code&gt;Redis&lt;/code&gt;  内存生成一系列指令，然后将这些指令序列化到临时文件中，过程中的增量命令会同时写到&lt;strong&gt; aof 缓冲区&lt;/strong&gt;和&lt;strong&gt; aof 重写缓冲区&lt;/strong&gt;，会追加到临时文件中，最后替换 &lt;code&gt;AOF&lt;/code&gt;  文件。这里需要重点说一下，我们将数据写入到文件中时，其实是先写入到内核缓冲区，再到磁盘缓冲区，最后到磁盘，最后一个阶段我们是无法介入的，但是可以调用 &lt;code&gt;fsync()&lt;/code&gt;  强制将数据刷新到磁盘缓冲区。 &lt;code&gt;redis&lt;/code&gt;  默认是每秒调用一次。（有参数控制何时重写，比如文件大小超过多少，增量达到多少）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;混合持久化&lt;/code&gt; ：4.0 版本后还出现了混合持久化（混合持久化工作在 &lt;strong&gt;AOF 日志重写过程&lt;/strong&gt;。），该机制必须打开 &lt;code&gt;AOF&lt;/code&gt; ，（就是重写 aof 文件）隔一段时间拍摄快照，生成 &lt;code&gt;rdb&lt;/code&gt;  数据，两次快照之间的记录使用 &lt;code&gt;AOF&lt;/code&gt;  日志来记录，并追加到 &lt;code&gt;rdb&lt;/code&gt;  数据后面。恢复数据时，先回复 &lt;code&gt;rbd&lt;/code&gt;  数据，再执行 &lt;code&gt;AOF&lt;/code&gt;  日志。这种机制既解决了 &lt;code&gt;rdb&lt;/code&gt;  快照摄时突然断电导致整个快照丢失（因为还在临时文件中），也解决了 &lt;code&gt;AOF&lt;/code&gt;  文件太大，不断重写的性能消耗。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9wZGFpLnRlY2gvbWQvZGIvbm9zcWwtcmVkaXMvZGItcmVkaXMteC1yZGItYW9mLmh0bWwjcmRiJUU1JTkyJThDYW9mJUU2JUI3JUI3JUU1JTkwJTg4JUU2JTk2JUI5JUU1JUJDJThGLTQtMCVFNyU4OSU4OCVFNiU5QyVBQw==&#34;&gt;Redis 进阶 - 持久化&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvT19xRGNvNi1EYXN1M1JvbVdJS19JZw==&#34;&gt;https://mp.weixin.qq.com/s/O_qDco6-Dasu3RomWIK_Ig&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  的大 &lt;code&gt;key&lt;/code&gt;  对持久化有什么影响？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先大 &lt;code&gt;key&lt;/code&gt;  不是指 &lt;code&gt;key&lt;/code&gt;  的长度很大或者字面量很大，而是指对应的 &lt;code&gt;value&lt;/code&gt;  占用内存很大。&lt;/p&gt;
&lt;p&gt;大 &lt;code&gt;key&lt;/code&gt;  在 &lt;code&gt;aof&lt;/code&gt;  机制写入命令时，如果是 &lt;code&gt;Always&lt;/code&gt;  机制，那么调用 &lt;code&gt;fsync()&lt;/code&gt;  函数，将数据从内核缓冲区写入磁盘时，必须等待写完函数才会返回，如果是大 &lt;code&gt;key&lt;/code&gt; ，数据量很大，自然就会导致长时间阻塞。如果是 &lt;code&gt;Everysec&lt;/code&gt;  机制，因为是创建异步任务调用 &lt;code&gt;fsync&lt;/code&gt; ，所以不会影响主线程。&lt;/p&gt;
&lt;p&gt;同时，如果 &lt;code&gt;redis&lt;/code&gt;  存储了很多大 &lt;code&gt;key&lt;/code&gt; ，一方面会使 &lt;code&gt;aof&lt;/code&gt;  文件频繁重写，另一方面会导致主线程对应的页表越大， &lt;code&gt;rdb&lt;/code&gt;  异步快照和 &lt;code&gt;aof&lt;/code&gt;  重写都会 &lt;code&gt;fork&lt;/code&gt;  一个子线程，就需要为子线程复制一份页表，页表越大，复制过程就越长，主线程阻塞在 &lt;code&gt;fork&lt;/code&gt;  调用就越久。&lt;/p&gt;
&lt;h1 id=&#34;高可用篇&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#高可用篇&#34;&gt;#&lt;/a&gt; 高可用篇&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  如何保证数据一致性？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先，很难保证缓存和数据库 100% 数据一致，因为我们引入 &lt;code&gt;Redis&lt;/code&gt;  本身是为了性能，花很大代价完全保证数据一致性，有时性能反而还会下降，只能说尽量吧。&lt;/p&gt;
&lt;p&gt;考虑到并发，面对更新请求，我了解到的解决方案就是：先更新数据库再删除缓存（也有问题，但是相对概率很小）。如果是更新数据库 + 更新缓存，并发问题很大（先更新的会覆盖后更新的缓存），哪怕是先删除缓存再更新数据库（A 先读，B 修改删除了缓存，再更新数据库，A 将读到的旧数据再写入缓存），也存在并发问题，因为从数据库拿数据到缓存中是两步：从数据库读取，写到缓存中。只要不是原子操作，在并发环境就可能导致数据不一致。&lt;/p&gt;
&lt;p&gt;再考虑到删除缓存操作可能会失败，现在的解决方案一般是使用消息队列或者订阅数据库变更日志再操作缓存（canal）。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvRDRJazZsVEFfeVNCT3lEM3dhTmoxdw==&#34;&gt;https://mp.weixin.qq.com/s/D4Ik6lTA_ySBOyD3waNj1w&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  内存淘汰是怎么一回事？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先 &lt;code&gt;Redis&lt;/code&gt;  对于过期了的 &lt;code&gt;key&lt;/code&gt;  采用两种策略：惰性删除和定期删除。所以当内存耗尽时， &lt;code&gt;Redis&lt;/code&gt;  存在过期 / 没过期两种键，所以删除策略也有不同，有 8 种：直接返回错误 / 删除 LRU、LFU 最早的过期（所有）key / 随机删除过期（所有）key&lt;/p&gt;
&lt;p&gt;传统的 &lt;code&gt;LRU&lt;/code&gt;  存在存储、误删的缺点，所以 &lt;code&gt;Redis&lt;/code&gt;  配置文件定义了一个属性，默认为 5，会取出 5 个的 &lt;code&gt;key&lt;/code&gt; ，按照 &lt;code&gt;LRU&lt;/code&gt;  算法删除对应 &lt;code&gt;key&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;至于 &lt;code&gt;LFU&lt;/code&gt; ， &lt;code&gt;Redis&lt;/code&gt;  也是采用了一些随机算法的策略，因为在 &lt;code&gt;RedisObject&lt;/code&gt;  中有个 &lt;code&gt;lru&lt;/code&gt;  属性，前 &lt;code&gt;24bit&lt;/code&gt;  用于记录 &lt;code&gt;LRU&lt;/code&gt; ，后 &lt;code&gt;8bit&lt;/code&gt;  记录 &lt;code&gt;LFU&lt;/code&gt;  的访问热度。 &lt;code&gt;8bit&lt;/code&gt;  最多表示 255，所以不能单纯的访问一次就自增，而是通过比较两个参数：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从 0~1 随机生成一个随机数 &lt;code&gt;R&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;配置中有一个 &lt;code&gt;factory&lt;/code&gt;  参数，用于计算 &lt;code&gt;P = 1 / (差值*factory+1)&lt;/code&gt; 。这里的差表示当前热度减去初始值。&lt;/li&gt;
&lt;li&gt;如果 &lt;code&gt;P&amp;gt;R&lt;/code&gt; ，热度 + 1，反之 + 0。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可以看出，热度越高，那么上升的概率越小。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvLWNhTVRyT1hRdS1vME80NGU2STlkUQ==&#34;&gt;https://mp.weixin.qq.com/s/-caMTrOXQu-o0O44e6I9dQ&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  主从复制原理是什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;主节点和从节点的数据交互方式分为全量复制和增量复制。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全量复制：在从节点与主节点建立连接（tcp 长连接）时，从节点先发送 &lt;code&gt;sync&lt;/code&gt; ，主节点会执行 bgsave 生成 rdb 文件再发送，使得从节点加载并初始化数据。在生成 &lt;code&gt;rdb&lt;/code&gt;  时新来的写命令请求会放在一个缓冲区，等 &lt;code&gt;rdb&lt;/code&gt;  传输完了就会传输这个缓冲区数据到 &lt;code&gt;salve&lt;/code&gt;  中。这个缓冲区就是 &lt;code&gt;replication buffer&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;增量复制：如果从节点（ &lt;code&gt;client&lt;/code&gt; ）和主节点不断开连接，那么就可以一直通过 &lt;code&gt;replication buffer&lt;/code&gt; （如果满了就会断开连接，删除缓存，重连）传输数据，但是如果连接不小心断开了， &lt;code&gt;replication buffer&lt;/code&gt;  就会被释放。此时就需要&lt;strong&gt;增量复制&lt;/strong&gt;。在建立主从连接时，双方会维护一个 &lt;code&gt;offset&lt;/code&gt; ，在主节点将写操作记录到 &lt;code&gt;replication buffer&lt;/code&gt;  时，还会记录到 &lt;code&gt;repl_backlog_buffer&lt;/code&gt;  环形缓冲区，从节点维护的 &lt;code&gt;offset&lt;/code&gt;  就是同步数据的偏移量。主节点维护的 &lt;code&gt;master_repl_offset&lt;/code&gt;  就是环形缓冲区的当前数据的偏移，当从节点重新连接，发现 &lt;code&gt;master&lt;/code&gt;  的 &lt;code&gt;offset&lt;/code&gt;  没有覆盖自己维护的 &lt;code&gt;offset&lt;/code&gt; ，就可以进行增量复制，如果覆盖了，就走全量复制。（ &lt;code&gt;abs(m_offset-s_offset) &amp;lt; len&lt;/code&gt; ）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9qdWVqaW4uY24vcG9zdC82OTgxNzQ0NjMxMDAwMDcyMjA1&#34;&gt;https://juejin.cn/post/6981744631000072205&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  集群中如何判断某个节点是否正常工作？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一般是一半以上的主节点 &lt;code&gt;ping&lt;/code&gt;  一个节点都超时时，就会认为该节点挂了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主节点会默认每 &lt;code&gt;10s&lt;/code&gt; （可以通过参数 &lt;code&gt;repl-ping-slave-period&lt;/code&gt;  控制）向从节点发送 &lt;code&gt;ping&lt;/code&gt;  命令，从而判断从节点存活性和连接状态。&lt;/li&gt;
&lt;li&gt;从节点每 1 秒向主节点发送 &lt;code&gt;replconf ack&lt;/code&gt;  命令，给主节点报告自己的复制偏移量。一方面检测网络状态，另一方面检测数据复制情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  的脑裂现象了解过吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在 &lt;code&gt;Redis&lt;/code&gt;  集群中，如果主节点 A 因为网络问题和集群失联了，但是客户端还在不断往主节点 A 写入数据。哨兵发现后选举出新的主节点 B，然后 A 网络恢复后降级为从节点 A，此时需要主从同步，从节点 A 需要先清空数据再获取主节点 B 的 &lt;code&gt;rdb&lt;/code&gt;  文件。这就导致之前客户端写的数据没了，这其实也是一种数据不一致问题。&lt;/p&gt;
&lt;p&gt;解决方案为：如果主节点的连接的从节点少于 N 个（ &lt;code&gt;min-slaves-to-write&lt;/code&gt; ）或者主从同步的延迟高于 x（ &lt;code&gt;min-slaves-max-lag&lt;/code&gt; ），就禁止客户端写入数据。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;  的哨兵机制了解过吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;哨兵机制可以检测集群中主节点存活情况，如果主节点挂了，可以选举一个从节点为新的主节点，并把新的主节点的信息通知给客户端和其他从节点。所以哨兵主要负责：监控、选主、通知。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;监控&lt;/strong&gt;：哨兵每隔 1 秒就会向节点发送 &lt;code&gt;ping&lt;/code&gt;  命令，如果节点回复超时（ &lt;code&gt;down-after-milliseconds&lt;/code&gt;  配置选项），就判定该节点&lt;strong&gt;主观下线&lt;/strong&gt;。对于主节点而言，还有&lt;strong&gt;客观下线&lt;/strong&gt;，就是主节点没有挂，因为服务器压力或者网络问题导致回复超时，如果哨兵集群超过一半都回复超时就会判定为&lt;strong&gt;客观下线&lt;/strong&gt;。如果主节点并没有挂，那么超过一半的哨兵都回复超时的概率也比较低，这都是为了减少误判的概率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;选主&lt;/strong&gt;：当哨兵发现主节点挂了，就会问其他哨兵是否觉得主节点挂了，超过一半那么该节点就认为其&lt;strong&gt;客观下线&lt;/strong&gt;，然后该哨兵就会成为候选者，向其他哨兵请求投票，如果票数超过一半 (票数超过 &lt;code&gt;quorum = n/2+1&lt;/code&gt; ) ，就会作为 &lt;code&gt;leader&lt;/code&gt;  进行主从故障转移，选举出新的主节点。选举主节点的过程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从节点中选一个升级为主节点（从节点的网络状态，优先级，复制进度，ID 选出最合适的）&lt;/li&gt;
&lt;li&gt;让其他从节点修改复制目标，复制新的主节点&lt;/li&gt;
&lt;li&gt;将新的主节点的 IP 和信息通过发布者 / 订阅者机制通知给客户端&lt;/li&gt;
&lt;li&gt;继续监控旧主节点，一旦恢复上线，将其降为从节点&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;通知&lt;/strong&gt;：客户端通过发布者 / 订阅者机制知道新选举出来的主节点。主从节点切换完后会在 &lt;code&gt;+switch-master&lt;/code&gt;  频道发布新主节点的 IP 地址和信息。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;哨兵集群之间是如何通信的？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在搭建主从集群的哨兵集群时，每个哨兵只需要指定主节点名字、 &lt;code&gt;IP&lt;/code&gt; 、端口以及 &lt;code&gt;quorum&lt;/code&gt; ，哨兵之间就是通过 &lt;code&gt;Redis&lt;/code&gt;  的发布者 / 订阅者机制通信的。主节点有一个 &lt;code&gt;_sentinel_:hello&lt;/code&gt; ，各个哨兵把自己的 IP 和信息发布到 &lt;code&gt;_sentinel_:hello&lt;/code&gt;  频道，其他哨兵就可以获取信息进行通信。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;redis 集群中，为什么是每个主节点分配一系列个槽而不是每个主节点分配一个槽？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个问题涉及到 redis 的设计问题，大家可以开放性回答，但一定要言之有理，因为面试官往往会深问下去，如果你的想法很片面，往往无法回答面试官下一个问题。我谈谈我的理解，不一定全面，也不一定完全正确，大家要有自己的理解。&lt;/p&gt;
&lt;p&gt;首先，我们搭建 redis 集群往往是为了服务的高可用，比如一个 redis 一般是一秒 10 万的处理级别，但是当一瞬间请求特别高（比如双十一秒杀），一个 redis 也扛不住。所以需要搭建 redis 集群。这就涉及到数据该放到哪一个主节点中，于是就有了分槽的机制。redis 并没有把分槽机制写死，默认的分槽机制就是：每个主节点的槽数 =（总槽数 / 主节点个数）。然后一个请求过来，先看它的 key，将 key 做 CRC 冗余检验并取模看看这个 key 属于哪个槽从而判断这个 key（请求）属于哪个主节点。那么看到这里，其实每个主节点只分一个槽，然后主节点总数作为槽的总数其实也是没问题的。&lt;/p&gt;
&lt;p&gt;美团二面问我这个，我当时回答的是：一个主节点分配多个槽，&lt;strong&gt;可能&lt;/strong&gt;是为了让请求分布更均匀。这个回答就很浅，所以他就继续问：你能说说这个过程吗，为什么一个节点有多个槽，他就分配均匀？我直接懵逼。&lt;/p&gt;
&lt;p&gt;// &lt;strong&gt;以下内容付费可见，如果面试被问到了这个题，记得请我吃饭&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我下来自己思考的思路如下：一个节点多个槽比一个节点一个槽，redis 多出来的机制是什么？很显然，槽越多，越好分配。我们可以自己分配每个节点的槽有哪些，这个很重要，如果每个主节点只有一个槽，那么是不可能有自定义分配机制的。那么为什么要自定义分配机制呢？比如我有很多个热点数据 key，我一个 redis 可能可以抗住三四个热点数据的请求，那么如果我所有的热点数据都落在了一个 redis 怎么办？那么我搭建集群不就没有意义了吗？所以我就可以分槽，这些热点数据可能数据槽 A，槽 B，槽 C，我就可以把这些槽分配到不同的 redis 节点中，&lt;strong&gt;这样就使得请求均匀到不同的节点中&lt;/strong&gt;。现在我们假设每个主节点只能分配一个槽，如果这些热点数据取模后都落在了一个主节点上，我们是没有太多手段来解决这个问题的（当然可以增加主节点个数，使得取模的总数不相同，但是一方面解决方法不如自定义槽分配优雅，另一个方面就是集群中节点个数不可能太大，那么热点 key% 总数落到同一个节点的概率也很大）。&lt;/p&gt;
&lt;p&gt;这就是我个人的理解，回顾我的美团二面，第一个问题是&lt;strong&gt; MySQL 集群中有多个主节点，从节点应该听谁的，或者说多个主节点如何保持数据一致&lt;/strong&gt;，一开始 hr 的问题描述就在带偏我，正确的问法也不是这么问的，但是我太在意这次面试了，根本没有好好冷静思考，导致我越说越混乱，第二个问题就是&lt;strong&gt; redis 的槽分配&lt;/strong&gt;，以前我也注意到槽这个问题的，但是从来没有深究过，我确实没想到会问的这么细，第三个问题就是&lt;strong&gt;从全国身份证号查询一个给定身份证号&lt;/strong&gt;，有什么好的思路，这个也是意难平，因为听到这个问题，我就想到了 redis 的一个最基本的设计机制：我传入 key，redis 是如何&lt;strong&gt;快速&lt;/strong&gt;在&lt;strong&gt;内存&lt;/strong&gt;中找到的？答案是 redis 存储 key 在最底层用了字典，可是我老早就听到了字典这个概念，一直没想着去了解它 (md 就是一棵树)，但是&lt;strong&gt;计算机的知识就是这样，很多你一听就知道，但是没听过就根本无法想象还有这样一种思路&lt;/strong&gt;。最后面试官给了我一个&lt;strong&gt;困难题算法&lt;/strong&gt;，我没写出来，最可气的就是当天晚上我在力扣上搜到这道题，冷静下来后一会就 AC 了。这次面试真的是意难平，我老跟同学、家人说那个 hr 面的太难了，问的都是一些业务、设计类题目，不去实习，不去真正做一下很难知道这些思路，但是现在反思一下，我太在意这次的面试了，如果我冷静一点，就不会像现在这样，叹气说一声，苍天悠悠，何薄于我。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://cecilia.cool/2023/03/05/%E5%85%AB%E8%82%A1%E6%96%87/Java/</guid>
            <title>Java</title>
            <link>https://cecilia.cool/2023/03/05/%E5%85%AB%E8%82%A1%E6%96%87/Java/</link>
            <category>八股文</category>
            <pubDate>Sun, 05 Mar 2023 10:02:30 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;基础&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#基础&#34;&gt;#&lt;/a&gt; 基础&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;1. 谈谈深拷贝和浅拷贝&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;浅拷贝：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝，此为浅拷贝。&lt;/li&gt;
&lt;li&gt;深拷贝：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象，并复制其内容，此为深拷贝。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 &lt;code&gt;Object&lt;/code&gt;  类中，有个 &lt;code&gt;clone()&lt;/code&gt;  方法，默认的就是浅拷贝，一个类想要重写 &lt;code&gt;clone()&lt;/code&gt;  函数，需要实现 &lt;code&gt;Cloneable&lt;/code&gt;  接口，自己实现深拷贝，就可以在 &lt;code&gt;clone&lt;/code&gt;  函数中直接 &lt;code&gt;new&lt;/code&gt;  就行。序列化也是深拷贝，这里直接给代码：&lt;/p&gt;
&lt;figure class=&#34;highlight java&#34;&gt;&lt;figcaption data-lang=&#34;java&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;DeepClone&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;implements&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;Serializable&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;     &lt;span class=&#34;token keyword&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;final&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;long&lt;/span&gt; serialVersionUID &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;1412L&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;     &lt;span class=&#34;token keyword&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;Object&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;deepClone&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;throws&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;          &lt;span class=&#34;token comment&#34;&gt;// 序列化，将数据存到 bos 中&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;6&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;          &lt;span class=&#34;token class-name&#34;&gt;ByteArrayOutputStream&lt;/span&gt; bos &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;ByteArrayOutputStream&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;7&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;          &lt;span class=&#34;token class-name&#34;&gt;ObjectOutputStream&lt;/span&gt; oos &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;ObjectOutputStream&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;bos&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;8&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;          oos&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;writeObject&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token keyword&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;9&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;          &lt;span class=&#34;token comment&#34;&gt;// 反序列化&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;10&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;          &lt;span class=&#34;token class-name&#34;&gt;ByteArrayInputStream&lt;/span&gt; bis &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;ByteArrayInputStream&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;bos&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;toByteArray&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;11&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;          &lt;span class=&#34;token class-name&#34;&gt;ObjectInputStream&lt;/span&gt; ois &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;ObjectInputStream&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;bis&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;12&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;          &lt;span class=&#34;token keyword&#34;&gt;return&lt;/span&gt; ois&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;readObject&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;13&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;     &lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;14&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;这里解释一下序列化的两个类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ByteArrayOutputStream&lt;/code&gt; ：提供了一个输出流的实现，将数据写入一个字节数组。它是 &lt;code&gt;OutputStream&lt;/code&gt;  的子类，当您需要将数据写入字节数组而不是文件或其他输出流时， &lt;code&gt;ByteArrayOutputStream&lt;/code&gt;  非常有用&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ObjectOutputStream&lt;/code&gt; ：它提供了一个输出流的实现，将对象写入一个字节流。它是 &lt;code&gt;OutputStream&lt;/code&gt;  的子类，提供了向字节流写入对象和检索字节流内容的方法。 &lt;code&gt;ObjectOutputStream&lt;/code&gt;  可以与 &lt;code&gt;ByteArrayOutputStream&lt;/code&gt;  一起使用，将对象写入字节数组而不是文件或其他输出流。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;集合&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#集合&#34;&gt;#&lt;/a&gt; 集合&lt;/h1&gt;
&lt;p&gt;涉及到 Java 集合部分，也包括线程安全的集合，还是以面试题的形式记录。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1. &lt;code&gt;ArrayList&lt;/code&gt;  和 &lt;code&gt;LinkedList&lt;/code&gt;  遍历谁更快？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;ArrayList&lt;/code&gt;  更快， &lt;code&gt;ArrayList&lt;/code&gt;  的优势就是内存连续，如果遍历 &lt;code&gt;LinkedList&lt;/code&gt; ，随机 IO 可能更多一些&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2. 谈谈你对 &lt;code&gt;ArrayList&lt;/code&gt;  的理解&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从我学习程度来看， &lt;code&gt;ArrayList&lt;/code&gt;  需要注意的是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程不安全，如果要保证安全，可以使用 &lt;code&gt;Vector&lt;/code&gt;  或者使用 &lt;code&gt;Collections.synchronizedList(xx)&lt;/code&gt; ，前者在每个操作方法上都加了 &lt;code&gt;synchronized&lt;/code&gt;  关键字，后者内部会维护一个排他锁，每次对集合操作时，都需要先竞争锁。&lt;/li&gt;
&lt;li&gt;迭代器的 &lt;code&gt;fail-fast&lt;/code&gt;  机制：这其实是每个实现了 &lt;code&gt;iterator&lt;/code&gt;  集合都需要注意的地方，每次对数组进行增删，都会使得 &lt;code&gt;modCount++&lt;/code&gt; ，而迭代器的 &lt;code&gt;next&lt;/code&gt;  函数会检测 &lt;code&gt;modCount&lt;/code&gt;  是否和最开始的自己保存的 &lt;code&gt;modCount&lt;/code&gt;  相同，也就是检测在迭代的过程中数组是否发生了改变，&lt;strong&gt;因为这可能使得迭代过程中漏了某些元素或者重复遍历某些元素&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ArrayList&lt;/code&gt;  内部是使用 &lt;code&gt;Object&lt;/code&gt;  数组 -- &lt;code&gt;elementData&lt;/code&gt; ，但是该变量没有被 &lt;code&gt;private&lt;/code&gt;  修饰，代码注释写的是方便内部类更快的访问该属性，如果被 &lt;code&gt;private&lt;/code&gt;  修饰，那么同样的代码反编译后的字节码文件更复杂一些。&lt;/li&gt;
&lt;li&gt;扩容时，是 1.5 倍增长，而 &lt;code&gt;Vector&lt;/code&gt;  扩容默认两倍扩容。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;3. &lt;code&gt;HashMap&lt;/code&gt;  了解吗？1.7 版本和 1.8 版本都什么区别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;JDK1.7&lt;/code&gt;  的 &lt;code&gt;HashMap&lt;/code&gt;  使用的是数组桶加链表，如果链表过长，那么时间复杂度会退化为 O (n)，而 1.8 使用的引入了红黑树，当链表节点为 8 时，就转为红黑树。至于为什么是 8，估计也是个统计概率值。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;1.7&lt;/code&gt;  节点插入时使用的是头插法，而 1.8 使用的是尾插法，头插在并发环境下容易出现环导致死循环，具体形成原因我并没有仔细研究，因为我认为 &lt;code&gt;HashMap&lt;/code&gt;  本身就是线程不安全的，无论是头插还是尾插，在并发环境下都不能使用 &lt;code&gt;HashMap&lt;/code&gt; ，曾经也有人向社区报告 &lt;code&gt;bug&lt;/code&gt;  说 1.7 的 &lt;code&gt;HashMap&lt;/code&gt;  尾插会在并发环境下出现死循环，但是社区并没有管，而是回复 “ &lt;code&gt;HashMap&lt;/code&gt;  本来就不是给你在并发环境用的，想要安全请使用 &lt;code&gt;ConcurrentHashMap&lt;/code&gt; ”。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;4. &lt;code&gt;HashMap&lt;/code&gt;  扩容机制了解过吗，为什么容量大小必须是 2 的指数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;HashMap&lt;/code&gt;  的容量大小默认是 16，阿里巴巴开发规范插件提示在初始化 &lt;code&gt;HashMap&lt;/code&gt;  时尽量指定容量大小（预计存储个数 / 负载因子 + 1），因为没有指定可能会导致多次扩容，这个涉及到重建 &lt;code&gt;Hash&lt;/code&gt;  表，链表分拆的操作，比较耗时。如果构造函数传入的容量不是 2 的指数，那么会将容量设置为既是 2 的指数，又是大于传入参数的最小数。&lt;/p&gt;
&lt;p&gt;至于为什么是 2 的指数，涉及 &lt;code&gt;hash&lt;/code&gt;  公式，也就是 &lt;code&gt;index = hash &amp;amp; (len - 1)&lt;/code&gt; ，这个公式其实就相当于用长度取模 &lt;code&gt;index = hash % len&lt;/code&gt; ，只不过位运算快很多。扩容机制为两倍扩容，公式为 &lt;code&gt;newCap = 2 * oldCap&lt;/code&gt; ，我们假设下标为 &lt;code&gt;i&lt;/code&gt;  的那一部分，这个部分的链表的节点都满足 &lt;code&gt;hash / len = y ... i&lt;/code&gt; ，也就是说，我们假设商为 &lt;code&gt;y&lt;/code&gt; ，那么当商为奇数时（ &lt;code&gt;hash &amp;amp; oldCap == 1&lt;/code&gt; ），扩容后再使用 &lt;code&gt;hash&lt;/code&gt;  公式得到的结果就是 &lt;code&gt;i+n&lt;/code&gt; ，如果商为偶数的话，扩容后再 &lt;code&gt;hash&lt;/code&gt;  的结果还是 &lt;code&gt;i&lt;/code&gt; 。这就使得每次扩容，都将现有的链表拆为两部分，一部分留在当前下标，另一部分转移到扩容后的 &lt;code&gt;i+n&lt;/code&gt;  处，这种机制使用扩容时逻辑简单，操作迅速，还使得数组中节点分布均匀，不会出现那种节点都分布在前半部分或者后半部分。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;5. 为什么重写 &lt;code&gt;equals&lt;/code&gt;  方法的同时建议重写 &lt;code&gt;hashCode方法&lt;/code&gt; ，能用 &lt;code&gt;HashMap&lt;/code&gt;  举个例子吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们假设一个类为 &lt;code&gt;People&lt;/code&gt; ，只有一个属性 &lt;code&gt;name&lt;/code&gt; ，那么现实情况下，两个对象相等，要么他们内存地址相同，要么 &lt;code&gt;equals&lt;/code&gt;  比较后相同，这里也就是 &lt;code&gt;name&lt;/code&gt;  相同。如果不重写 &lt;code&gt;hashCode&lt;/code&gt;  方法，也就是使用 &lt;code&gt;Object&lt;/code&gt;  内置的方法。现在有两个内存地址不同的 &lt;code&gt;People&lt;/code&gt;  对象， &lt;code&gt;name&lt;/code&gt;  相同使得 &lt;code&gt;equals&lt;/code&gt;  相同，但是 &lt;code&gt;hashCode&lt;/code&gt;  却不相同，那么当这两个对象作为 &lt;code&gt;Key&lt;/code&gt;  加入到 &lt;code&gt;HashMap&lt;/code&gt;  时，我们希望的是后加入的对象会覆盖前面加入的，因为两个对象是相同的，但是因为 &lt;code&gt;hashCode&lt;/code&gt;  不同，他们两个甚至连映射出来的数组下标都不同，是无法覆盖的。这也就导致 &lt;code&gt;HashMap&lt;/code&gt;  中有两个相同的 &lt;code&gt;key&lt;/code&gt; ，这明显不符合哈希表的定义。&lt;/p&gt;
&lt;p&gt;再来看 &lt;code&gt;HashMap&lt;/code&gt;  的源码，为了实现覆盖操作，首先就要使得 &lt;code&gt;equals&lt;/code&gt;  相同的对象 &lt;code&gt;hashCode&lt;/code&gt;  也相同才一定能映射到同样的下标，然后顺着链表向下查找，如果 &lt;code&gt;HashCode&lt;/code&gt;  相同，同时 &lt;code&gt;equals&lt;/code&gt;  也相同就会覆盖，反之如果遍历了整个链表都没有这样的节点，就算做新增节点，尾插到链表中。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;6. 说说 &lt;code&gt;HashMap&lt;/code&gt;  与 &lt;code&gt;HashTable&lt;/code&gt;  的区别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;并发： &lt;code&gt;HashTable&lt;/code&gt;  用于并发环境，通过在方法上加入 &lt;code&gt;synchronized&lt;/code&gt;  关键字保证线程安全，但是并行度太低了，所以大多数都使用 &lt;code&gt;ConcurrentHashMap&lt;/code&gt; 。而 &lt;code&gt;HashMap&lt;/code&gt;  是线程不安全的。&lt;/li&gt;
&lt;li&gt;存储： &lt;code&gt;HashTable&lt;/code&gt;  键值对不允许存储 &lt;code&gt;null&lt;/code&gt; ，而 &lt;code&gt;HashMap&lt;/code&gt;  却可以， &lt;code&gt;HashTable&lt;/code&gt;  源码中会先判断 &lt;code&gt;value&lt;/code&gt;  是不是 &lt;code&gt;null&lt;/code&gt; ，从而抛出空指针异常，并且会直接调用 &lt;code&gt;key&lt;/code&gt;  的 &lt;code&gt;hashCode&lt;/code&gt;  方法，计算比较粗暴，而 &lt;code&gt;HashMap&lt;/code&gt;  统一指定 &lt;code&gt;key==null&lt;/code&gt;  时 &lt;code&gt;hashCode&lt;/code&gt;  为 0，至于 &lt;code&gt;value&lt;/code&gt;  是否为 &lt;code&gt;null&lt;/code&gt;  完全不重要，因为插入删除过程都不会涉及到 &lt;code&gt;value&lt;/code&gt; ，只会比较 &lt;code&gt;key&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;迭代： &lt;code&gt;HashTable&lt;/code&gt;  有两个迭代器， &lt;code&gt;Enumeration&lt;/code&gt;  使用的是安全失败机制（ &lt;code&gt;fail-safe&lt;/code&gt; ），而 &lt;code&gt;Iterator&lt;/code&gt;  是快速失败机制。 &lt;code&gt;HashMap&lt;/code&gt;  使用的是快速失败机制。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;7. 刚才提到 &lt;code&gt;ConcurrentHashMap&lt;/code&gt; ，你知道什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvTXk0UF9CQlhEbkFHWDFnaDYzMFpLdw==&#34;&gt;https://mp.weixin.qq.com/s/My4P_BBXDnAGX1gh630ZKw&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这个也要分 &lt;code&gt;1.7&lt;/code&gt;  和 &lt;code&gt;1.8&lt;/code&gt;  两个版本：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;1.7&lt;/code&gt;  使用的是数组桶 + 链表，分段，段数决定并行度。通俗来讲， &lt;code&gt;1.7&lt;/code&gt;  版本维护了一个数组，数组中每个元素都是一个 &lt;code&gt;HashMap&lt;/code&gt; ，上锁就是对每个段上锁。所以并行度并不高&lt;/li&gt;
&lt;li&gt;&lt;code&gt;1.8&lt;/code&gt;  使用的是数组桶 + 链表（升级红黑树），同时锁的粒度更小了，使用 &lt;code&gt;CAS+synchronized&lt;/code&gt;  来实现并发安全。维护的数组和 &lt;code&gt;HashMap&lt;/code&gt;  的数组是一致的，只不过每次上锁都是对要修改的下标单个元素进行上锁。由于 &lt;code&gt;Synchronized&lt;/code&gt;  的性能采用锁升级的方式优化后， &lt;code&gt;ConcurrentHashMap&lt;/code&gt;  的性能也随之上升。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;至于 &lt;code&gt;CAS&lt;/code&gt;  操作，是对数组元素进行修改，也就是&lt;strong&gt;链表的表头&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;只要上了锁，保证了线程安全，其他的都和 &lt;code&gt;HashMap&lt;/code&gt;  没有太多区别，也就有些细节不同，比如 &lt;code&gt;HashMap&lt;/code&gt;  再加入一个键值对就要扩容了，它会先插入再扩容，而 &lt;code&gt;ConcurrenHashMap&lt;/code&gt;  是先扩容再插入。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;8. 这么了解 &lt;code&gt;ConcurrentHashMap&lt;/code&gt; ，你实际用过吗，或者你看源码有什么地方用过吗？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在日志框架中，日志门面 &lt;code&gt;slf4j-api&lt;/code&gt;  自带了一个实现，叫做 &lt;code&gt;slf4j-simple&lt;/code&gt; ，它在实现 &lt;code&gt;LoggerFactory&lt;/code&gt;  时就用到了 &lt;code&gt;ConcurrenMap&lt;/code&gt; ，键值对是 &lt;code&gt;&amp;lt;String,Logger&amp;gt;&lt;/code&gt; ，这里的 &lt;code&gt;String&lt;/code&gt;  对应的就是 &lt;code&gt;name&lt;/code&gt; 。当外界传给 &lt;code&gt;LoggerFactory&lt;/code&gt;  一个 &lt;code&gt;name&lt;/code&gt;  时，就会从 &lt;code&gt;ConcurrentHashMap&lt;/code&gt;  中找，如果有就返回，没有就新建一个，缓存起来再返回。&lt;/p&gt;
&lt;figure class=&#34;highlight java&#34;&gt;&lt;figcaption data-lang=&#34;java&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token keyword&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;SimpleLoggerFactory&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;implements&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;ILoggerFactory&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token class-name&#34;&gt;ConcurrentMap&lt;/span&gt;&lt;span class=&#34;token generics&#34;&gt;&lt;span class=&#34;token punctuation&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;token class-name&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;Logger&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;&gt;&lt;/span&gt;&lt;/span&gt; loggerMap &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;ConcurrentHashMap&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;4&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;SimpleLoggerFactory&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;5&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;        &lt;span class=&#34;token class-name&#34;&gt;SimpleLogger&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;lazyInit&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;6&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;7&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;8&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;Logger&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;getLogger&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token class-name&#34;&gt;String&lt;/span&gt; name&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;9&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;        &lt;span class=&#34;token class-name&#34;&gt;Logger&lt;/span&gt; simpleLogger &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token class-name&#34;&gt;Logger&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token keyword&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;loggerMap&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;name&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;10&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;        &lt;span class=&#34;token keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;simpleLogger &lt;span class=&#34;token operator&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;11&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;            &lt;span class=&#34;token keyword&#34;&gt;return&lt;/span&gt; simpleLogger&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;12&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;        &lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;13&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;            &lt;span class=&#34;token class-name&#34;&gt;Logger&lt;/span&gt; newInstance &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;token class-name&#34;&gt;SimpleLogger&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;name&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;14&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;            &lt;span class=&#34;token class-name&#34;&gt;Logger&lt;/span&gt; oldInstance &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token class-name&#34;&gt;Logger&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token keyword&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;loggerMap&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;putIfAbsent&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;name&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; newInstance&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;15&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;            &lt;span class=&#34;token keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token class-name&#34;&gt;Logger&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;oldInstance &lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;?&lt;/span&gt; newInstance &lt;span class=&#34;token operator&#34;&gt;:&lt;/span&gt; oldInstance&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;16&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;        &lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;17&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;18&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;19&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token keyword&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;reset&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;20&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;        &lt;span class=&#34;token keyword&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;loggerMap&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;token function&#34;&gt;clear&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;21&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;    &lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;22&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;&lt;span class=&#34;token punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;其实日志中使用 &lt;code&gt;ConcurrentHashMap&lt;/code&gt;  很正常，因为日志打印本身就经常处于并发环境中，有些甚至会专门分配线程去处理日志。有时类专门有一个 &lt;code&gt;Logger&lt;/code&gt; ，其对应键值就是类的全类限定名，多个线程可能都会请求这个 &lt;code&gt;logger&lt;/code&gt; ，自然就需要线程安全的容器来缓存。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://cecilia.cool/2023/02/27/%E5%85%AB%E8%82%A1%E6%96%87/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</guid>
            <title>计算机网络</title>
            <link>https://cecilia.cool/2023/02/27/%E5%85%AB%E8%82%A1%E6%96%87/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</link>
            <category>八股文</category>
            <pubDate>Mon, 27 Feb 2023 17:09:36 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;本文积累了作者在准备面试时学习的&lt;strong&gt;计算机网络&lt;/strong&gt;的知识与问题，作为科班出身，408 这些科目的重要性不必多说，能直接检验出你作为科班选手的水准。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1. 键入网址后依次发生了什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvSTZCTHdiSXBmR0VKbnhqRGNQWGMxQQ==&#34;&gt;https://mp.weixin.qq.com/s/I6BLwbIpfGEJnxjDcPXc1A&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;浏览器解析 URL 生成 Http 请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;发送 Http 请求前，会将域名解析为 IP 地址&lt;/strong&gt;，会先查询浏览器缓存、系统缓存、本机 &lt;code&gt;hosts&lt;/code&gt;  文件，如果没有，就会发送请求到本地域名服务器，通过本地域名服务器分别访问根域名服务器、顶级域名服务器、权威域名服务器，最终拿到域名映射的 IP 地址，并且缓存起来。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;建立 TCP 连接，三次握手&lt;/strong&gt;。三次握手是为了双方确定对方具有发送和接收数据的能力，所以两次握手不行&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;增加 TCP 头部&lt;/strong&gt;。如果 Http 数据太长，超过了 MSS（网络层数据大小），就需要将其切分再每个加上 TCP 头部。TCP 头部包含了源端口，目的端口，校验和，序号等信息，最后交给 IP 模块处理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;加上 IP 头部&lt;/strong&gt;。IP 头部包含了源地址和目的地址，如果主机有多个网卡，会根据路由表规则来选择网卡，其实就是目的地址与网卡的掩码做&lt;strong&gt;与运算&lt;/strong&gt;从而来选择，如果都不匹配，就会走默认网卡 0.0.0.0。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;加上 MAC 头部&lt;/strong&gt;。通过 ARP 协议来获取目的地址的 MAC 地址，如果 ARP 缓存有，就直接用，如果没有，就在以太网中广播目的地址从而得到响应拿到对应的 MAC 地址。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;将给网卡，将包转为电信号，通过网线发送出去&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;交换机拿到包，通过 MAC 表将数据从对应端口发送出去&lt;/strong&gt;，如果表中没有对应映射，就对局域网所有主机发送。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;路由器拿到包并根据 IP 地址进行转发&lt;/strong&gt;。MAC 头部作用就是将包送到路由器，然后 MAC 头部就会被丢弃。路由器根据路由表决定下一跳（下一跳的 IP）。通过 ARP 协议拿到下一跳的 MAC 地址，重新发送。整体传输过程只有 MAC 地址在不断变化，因为包需要不断在以太网中传输。&lt;/li&gt;
&lt;li&gt;服务器收到请求，回复 ACK 和 Http 响应。浏览器得到响应，再请求 html 中的 js，css 资源。浏览器再解析渲染，呈现网页。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;session&lt;/code&gt;  和 &lt;code&gt;cookie&lt;/code&gt;  的区别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Cookie&lt;/code&gt;  是保存在客户端的一小块文本串的数据。客户端向服务器发起请求时，服务端会向客户端发送一个 Cookie，客户端就把 Cookie 保存起来。在客户端下次向同一服务器再发起请求时，Cookie 被携带发送到服务器。服务器就是根据这个 Cookie 来确认身份的。&lt;/li&gt;
&lt;li&gt;session 指的就是服务器和客户端一次会话的过程。Session 利用 Cookie 进行信息处理的，当用户首先进行了请求后，服务端就在用户浏览器上创建了一个 Cookie，当这个 Session 结束时，其实就是意味着这个 Cookie 就过期了。Session 对象存储着特定用户会话所需的属性及配置信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要注意的是，浏览器第一次请求服务器时，服务器创建了 session，会给浏览器返回 sessionId，这也是放在 cookie 里面的，cookie 记录此 SessionId 是属于哪个域名，之后浏览器的请求会自动判断此域名下是否存在 Cookie 信息，如果存在，则自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到，说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。&lt;/p&gt;
&lt;h1 id=&#34;http协议&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#http协议&#34;&gt;#&lt;/a&gt; Http 协议&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;1. 谈谈 http 协议&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvQUsxUGI5cngwcTVIZjhkcTZITk9odw==&#34;&gt;https://mp.weixin.qq.com/s/AK1Pb9rx0q5Hf8dq6HNOhw&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;http 协议是超文本传输协议，一开始用于传输 html、css、js 等资源文件，后来也可以传输图片、视频、音频等。http1.0 是无状态的，每个 http 请求都必须重新建立 TCP 连接，这导致开销较大。http1.1 通过 &lt;code&gt;Cookie&lt;/code&gt;  来管理状态，同时实现了持久化连接。&lt;/p&gt;
&lt;p&gt;http 请求由：请求行、消息头、数据组成。请求行包括请求方法、&lt;strong&gt;URL&lt;/strong&gt;、协议版本。&lt;/p&gt;
&lt;p&gt;请求方法包括 GET（表单）、POST（实体）、DELETE（删除文件）、PUT（文件）、TRACE 等组成。&lt;/p&gt;
&lt;p&gt;状态码含义分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1xx：表示请求正在处理，是信息性状态码&lt;/li&gt;
&lt;li&gt;2xx：表示请求成功处理&lt;/li&gt;
&lt;li&gt;3xx：表示重定向&lt;/li&gt;
&lt;li&gt;4xx：表示客户端错误，请求不合法&lt;/li&gt;
&lt;li&gt;5xx：表示服务器错误，不能处理合法请求&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img data-src=&#34;https://s3.bmp.ovh/imgs/2023/04/18/79e38f25ac1d3bf9.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2. &lt;code&gt;GET&lt;/code&gt;  与 &lt;code&gt;POST&lt;/code&gt;  区别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;GET&lt;/code&gt;  的语义是从服务器获取指定的资源，请求的参数写在 &lt;code&gt;URL&lt;/code&gt;  中，浏览器一般对 &lt;code&gt;URL&lt;/code&gt;  的长度有一定的限制。 &lt;code&gt;GET&lt;/code&gt;  方法是 ** 安全、幂等（多次请求结果不变）** 的。请求的结果会被缓存。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;POST&lt;/code&gt;  的语义是根据报文 &lt;code&gt;body&lt;/code&gt; &lt;strong&gt; 对指定的资源做出修改&lt;/strong&gt;。 &lt;code&gt;POST&lt;/code&gt;  请求携带的数据一般是写在报文 &lt;code&gt;body&lt;/code&gt;  中。 &lt;code&gt;POST&lt;/code&gt;  方法不是安全、幂等的。请求的结果不会被主动缓存。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是实际开发中，很多人并没有遵循 &lt;code&gt;RFC&lt;/code&gt;  语义来实现 &lt;code&gt;GET&lt;/code&gt;  和 &lt;code&gt;POST&lt;/code&gt; 。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;长连接与短连接&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;http1.0 默认是短链接，但是可以设置头部的 &lt;code&gt;connection&lt;/code&gt;  字段为 &lt;code&gt;keep-alive&lt;/code&gt;  强制开启长连接。到了 http1.1 就是默认长连接了。 &lt;code&gt;keep-alive&lt;/code&gt;  也有三个参数： &lt;code&gt;tcp_keepalive_time&lt;/code&gt; 、 &lt;code&gt;tcp_keepalive_intvl&lt;/code&gt; 、 &lt;code&gt;tcp_keepalive_probes&lt;/code&gt; ：当 TCP 连接之后，闲置了 &lt;code&gt;tcp_keepalive_time&lt;/code&gt; ，则会发生侦测包，如果没有收到对方的 ACK，那么会每隔  &lt;code&gt;tcp_keepalive_intvl&lt;/code&gt;  再发一次，直到发送了 &lt;code&gt;tcp_keepalive_probes&lt;/code&gt; ，就会丢弃该连接。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;3. &lt;code&gt;Http&lt;/code&gt;  缓存技术&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;http&lt;/code&gt;  的缓存技术分为&lt;strong&gt;强制缓存&lt;/strong&gt;和&lt;strong&gt;协商缓存&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;强制缓存&lt;/strong&gt;：浏览器判断缓存没有过期，就直接使用缓存，是通过响应头部的两个字段实现的。 &lt;code&gt;Cache_Controller&lt;/code&gt;  是相对时间； &lt;code&gt;Expire&lt;/code&gt;  是一个绝对时间，如果两个字段同时存在于头部，那么 &lt;code&gt;Cache_Controller&lt;/code&gt;  的优先级更高。以 &lt;code&gt;Cache_Controller&lt;/code&gt;  为例，浏览器第一次访问资源，服务器返回资源的同时在头部加上 &lt;code&gt;Cache_Contorller&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;协商缓存&lt;/strong&gt;：有时响应返回的状态码为 &lt;code&gt;304&lt;/code&gt; ，其实就是服务端告知客户端是否可以使用缓存，这就是协商缓存。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;4. &lt;code&gt;Http&lt;/code&gt;  各版本之间的特性&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;http1.0&lt;/code&gt; ：短连接， &lt;code&gt;TCP&lt;/code&gt;  连接只处理一个请求，处理完就关闭连接。引入了 &lt;code&gt;POST&lt;/code&gt;  和 &lt;code&gt;HEAD&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http1.1&lt;/code&gt; ：通过 &lt;code&gt;Cookie&lt;/code&gt;  维护长连接，同时引入了 &lt;code&gt;PUT&lt;/code&gt; 、 &lt;code&gt;DELETE&lt;/code&gt; 、 &lt;code&gt;PATCH&lt;/code&gt;  等动词。&lt;strong&gt;使用管道可以同时发送多个请求&lt;/strong&gt;，减少整体响应时间（管道解决了&lt;strong&gt;请求&lt;/strong&gt;的队头阻塞，但是没有解决响应的队头阻塞，而且管道这个功能默认其实是不开启的，而且浏览器基本没有支持）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http2.0&lt;/code&gt; ：针对 &lt;code&gt;http&lt;/code&gt;  报文做出优化，如压缩首部，采用二进制报文格式，对计算机更友好。因为 &lt;code&gt;http1.1&lt;/code&gt;  默认不开启管道，浏览器也不支持， &lt;code&gt;http2.0&lt;/code&gt;  引入了 &lt;code&gt;Stream&lt;/code&gt;  概念，多个 &lt;code&gt;Stream&lt;/code&gt;  可以复用一个 &lt;code&gt;TCP&lt;/code&gt;  连接。不同的 &lt;code&gt;http&lt;/code&gt;  请求可以使用唯一的 &lt;code&gt;Stream ID&lt;/code&gt;  来区分，接收端通过 &lt;code&gt;Stream ID&lt;/code&gt;  组装 &lt;code&gt;http&lt;/code&gt;  消息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http3.0&lt;/code&gt; ：使用了基于 &lt;code&gt;UDP&lt;/code&gt;  实现的 &lt;code&gt;QUIC&lt;/code&gt;  协议， &lt;code&gt;http2.0&lt;/code&gt;  的缺点在于如果某一个 &lt;code&gt;Stream&lt;/code&gt;  在 &lt;code&gt;tcp&lt;/code&gt;  层有数据丢失，那么所有排在该 &lt;code&gt;Stream&lt;/code&gt;  后面的数据都要等待重传，应用层无法获取。 &lt;code&gt;http3.0&lt;/code&gt;  的每一个 &lt;code&gt;Stream&lt;/code&gt;  并不互相依赖，某一个 &lt;code&gt;Stream&lt;/code&gt;  数据丢失之后阻塞自己这个 &lt;code&gt;Stream&lt;/code&gt; 。其他特性还有更快的建立连接， &lt;code&gt;QUIC&lt;/code&gt;  包含了 &lt;code&gt;TLS&lt;/code&gt; ，只需要三次握手即可建立连接与密钥协商，而 &lt;code&gt;TCP&lt;/code&gt;  三次握手之后还需要额外的 &lt;code&gt;TLS&lt;/code&gt;  握手。由于 &lt;code&gt;QUIC&lt;/code&gt;  只是维护连接 &lt;code&gt;ID&lt;/code&gt; ，所以哪怕连接的主机 IP 变了（wifi 变流量），只要连接 ID 和上下文信息还在就不需要重新建立连接（ &lt;code&gt;TCP&lt;/code&gt;  的唯一标识是四元组，这种情况需要断开原来的连接，建立新的连接）。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;5. 说说如何优化 &lt;code&gt;http1.1&lt;/code&gt;  协议？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;优化 &lt;code&gt;http&lt;/code&gt;  协议的思路：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少 &lt;code&gt;http&lt;/code&gt;  请求次数：
&lt;ul&gt;
&lt;li&gt;使用缓存，将请求和响应的数据保存到本地磁盘，并设置过期时间。&lt;/li&gt;
&lt;li&gt;减少重定向次数，一般客户端和浏览器之间还会设置代理服务器，如果有资源的位置变了需要重定向，重定向的工作交给代理服务器做就可以减少 &lt;code&gt;http&lt;/code&gt;  请求。&lt;/li&gt;
&lt;li&gt;合并请求和懒加载。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;减少 &lt;code&gt;http&lt;/code&gt;  响应数据的大小：对数据使用无损压缩（谷歌的 br 压缩）或者有损压缩（谷歌的 &lt;code&gt;WebP&lt;/code&gt;  格式）。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;3. 谈谈 https 协议&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvMjFKYVh3ZGZTakl0ajVTZ093aGFwZw==&#34;&gt;https://mp.weixin.qq.com/s/21JaXwdfSjItj5SgOwhapg&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;数据传输使用的仍然是 http 协议，只不过使用了 SSL 对数据进行了加密，保证了数据传输的安全。&lt;/p&gt;
&lt;p&gt;其过程为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端发送 https 请求，服务端响应&lt;strong&gt; CA 证书和公钥&lt;/strong&gt;。（需要注意，是&lt;strong&gt;证书里面附带了公钥&lt;/strong&gt;）&lt;/li&gt;
&lt;li&gt;客户端校验 CA 证书合法性，生成随机密钥 key，并使用&lt;strong&gt;公钥&lt;/strong&gt;对 key 加密，再发送给服务端。&lt;/li&gt;
&lt;li&gt;服务端收到后，使用私钥对可 key 解密，拿到真正的 key，双方之后的数据传输就用该 key 进行&lt;strong&gt;对称加密传输&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述过程，如果没有 CA 证书，那么中间人攻击可以这样：在第一步将公钥换成自己的公钥 1，这样在第二步对客户端产生的 key 使用自己的私钥 1 解密从而拿到 key。最后再将 key 使用最开始服务端发送的公钥进行加密发送给服务端，这样 MITM（中间人攻击）照样可以完成。&lt;/p&gt;
&lt;p&gt;所以需要第三方的公信认证，CA 机构有一对公钥 / 私钥，公钥是对外界公开的，而私钥必须严格保密。当服务端将&lt;strong&gt; CA 证书 + 服务端公钥&lt;/strong&gt;发送给客户端时， 会先将证书的数据（包括服务端公钥）进行哈希，得到哈希值&lt;strong&gt; H&lt;/strong&gt;，再用私钥（CA 机构的私钥）将 H 加密，最后客户端（浏览器）拿到证书后，会使用系统浏览器内置的 CA 公钥对 H 进行解密得到 H，再自己通过证书指定的哈希算法对数据进行哈希得到&lt;strong&gt; H&#39;&lt;/strong&gt;，比较&lt;strong&gt; H==H&#39;&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;私钥和公钥可以互相加密解密，非不是私钥只能解密。上述过程，假设有中间人换了证书中的服务端公钥，也会因为不知道私钥而无法加密哈希值导致客户端会检测出来。所以 CA 机构应该严格保密私钥，如果泄露，就会失去公信力。&lt;/p&gt;
&lt;p&gt;如果整个 https 通信全部用非对称加密确实可以，双方各拿一对公钥 / 私钥，然后交换公钥进行通信。至于为什么本质还是要使用对称加密，是因为非对称加密太耗时间了，仅用于传输 key 即可。&lt;/p&gt;
&lt;h1 id=&#34;icmp&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#icmp&#34;&gt;#&lt;/a&gt; ICMP&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;4. 用过 ping 吗，说说原理&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvM0tGMEl4THVtOEVPdGNGMFpOSWlQQQ==&#34;&gt;https://mp.weixin.qq.com/s/3KF0IxLum8EOtcF0ZNIiPA&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ping&lt;/code&gt;  实现原理依托于 &lt;code&gt;ICMP&lt;/code&gt;  协议。该协议是互联网控制报文协议，用于报告网络错误、传送报文运输情况等。 &lt;code&gt;ICMP&lt;/code&gt;  报文被封装到 &lt;code&gt;IP&lt;/code&gt;  数据包里面。ping 使用的两种 &lt;code&gt;ICMP&lt;/code&gt;  数据包是&lt;strong&gt;回送请求&lt;/strong&gt;和&lt;strong&gt;回送响应&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;假设主机 A 对主机 B 进行了 ping 操作，那么主机 A 会封装 ** &lt;code&gt;ICMP&lt;/code&gt;  回送请求 **，此时会记录请求产生的时间，并将其封装到 IP 数据包中，再加上 MAC 头部，最后发送出去。没有缓存目的 MAC 地址，先通过 ARP 协议获取。&lt;/p&gt;
&lt;p&gt;主机 B 收到报文后，逐步拆除 MAC 和 IP 头部，经过地址检验后，将有用的信息提取交给 ICMP 协议，再发送 ** &lt;code&gt;ICMP&lt;/code&gt;  回送响应 **。主机 A 收到回送响应后，用当前时间减去 &lt;code&gt;ICMP&lt;/code&gt;  数据包发送时间，就可以得到 &lt;code&gt;RTT&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;同时， &lt;code&gt;ICMP&lt;/code&gt;  还维护了一个 &lt;code&gt;TTL&lt;/code&gt; ，每次数据包经过一个路由器，就会 - 1，直到为 0 被丢弃，TTL 就可以检测出两个主机之间经过多少跳。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;tracert&lt;/code&gt;  也是借助 &lt;code&gt;ICMP&lt;/code&gt;  协议实现的。&lt;/p&gt;
&lt;h1 id=&#34;tcpip&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#tcpip&#34;&gt;#&lt;/a&gt; TCP/IP&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;聊聊 TCP 三次握手和四次挥手&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvclgzQV9GQTE5bjRwSTlIaWNJRXNYZw==&#34;&gt;https://mp.weixin.qq.com/s/rX3A_FA19n4pI9HicIEsXg&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;TCP&lt;strong&gt; 三次握手&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;确认双方都有发送和接收数据的能力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;防止旧连接覆盖新连接。客户端知道自己此时应该建立哪个连接，但是网络传输过程复杂，很可能旧的连接 SYN 比新的 SYN 后到，到底建立哪个连接服务端是不知道的，所以必须有第三次握手，让客户端确认到底建立哪个连接。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;防止浪费资源。两次握手中，服务端不知道自己的 &lt;code&gt;ACK+SYN&lt;/code&gt;  是否被客户端收到，这会导致重复发送 &lt;code&gt;SYN+ACK&lt;/code&gt; ，建立很多个无用的连接。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同步初始化序列号。同步序列号能够防止接收端接收的数据乱序。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总的来说，第三次握手是必要的，&lt;strong&gt;必须由客户端确认建立连接的各种状态信息的正确性&lt;/strong&gt;。值得一提的是，第三次握手，发送方可以顺带发送数据。&lt;/p&gt;
&lt;p&gt;TCP&lt;strong&gt; 四次挥手&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;重点：主动放弃连接的一方会进入 &lt;code&gt;Time_Wait&lt;/code&gt;  状态，在 Linux 中，会等待 2MSL（60 秒）。&lt;/p&gt;
&lt;p&gt;四次挥手的过程为（假设客户端主动断开连接）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端发送 &lt;code&gt;Fin&lt;/code&gt;  表示自己断开连接，不再发送数据，但是可以接收数据，进入 &lt;code&gt;FIN_WAIT_1&lt;/code&gt;  状态。&lt;/li&gt;
&lt;li&gt;服务端收到 &lt;code&gt;Fin&lt;/code&gt; ，发送 &lt;code&gt;ACK&lt;/code&gt; ，表示自己收到断开请求，需要处理剩下的数据，进入 &lt;code&gt;CLOSED_WAIT&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;服务端处理完数据，发送 &lt;code&gt;Fin&lt;/code&gt; ，进入 &lt;code&gt;LAST_ACK&lt;/code&gt;  状态。&lt;/li&gt;
&lt;li&gt;客户端收到 &lt;code&gt;Fin&lt;/code&gt; ，发送 &lt;code&gt;ACK&lt;/code&gt; ，进入 &lt;code&gt;TIME_WAIT&lt;/code&gt;  状态，等待 &lt;code&gt;2MSL&lt;/code&gt; ，最后进入 &lt;code&gt;CLOSED&lt;/code&gt;  状态。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;正是因为服务端需要处理剩下数据，所以是四次挥手，同样，如果省去最后一次挥手，那么服务端就会一直处于 &lt;code&gt;LAST_ACK&lt;/code&gt;  状态，当客户端想建立新的连接，发送 &lt;code&gt;SYN&lt;/code&gt; ，服务端就会回复 &lt;code&gt;RST&lt;/code&gt; ，建立连接的过程会终止。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么四次挥手中要有 &lt;code&gt;TIME_WAIT&lt;/code&gt;  状态以及为什么要等 2MSL？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvclgzQV9GQTE5bjRwSTlIaWNJRXNYZw==&#34;&gt;https://mp.weixin.qq.com/s/rX3A_FA19n4pI9HicIEsXg&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我们这里默认主动断开连接的是客户端。首先，主动断开连接的那一方才会进入 &lt;code&gt;TIME_WAIT&lt;/code&gt; ，这个时间是 2MSL，在 Linux 中为 60s，而且这个时间是固定的，也就是在内核代码中写死了，无法修改。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;TIME_WAIT&lt;/code&gt;  的出现能够保证被动断开连接方（服务端）可以正常的关闭，从 &lt;code&gt;LAST_ACK&lt;/code&gt;  进入 &lt;code&gt;CLOSED&lt;/code&gt;  状态。&lt;/p&gt;
&lt;p&gt;MSL 是数据包在网络传输中存活的最长时间， &lt;code&gt;TIME_WAIT&lt;/code&gt;  设置为 2MSL，比较合理的解释为：如果服务端没有收到 &lt;code&gt;ACK&lt;/code&gt; ，超时重传 &lt;code&gt;FIN&lt;/code&gt;  后再接收 &lt;code&gt;ACK&lt;/code&gt;  的时间在 2MSL 之内。&lt;strong&gt;当客户端重新接收到 &lt;code&gt;FIN&lt;/code&gt;  时，会重置 2MSL 时间&lt;/strong&gt;。同时网络连接中的旧数据包在 2MSL 中能够被清理干净，如果客户端当前端口重新建立连接，不会有旧的数据传到当前端口，造成数据混乱。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;TIME_WAIT&lt;/code&gt;  出现的原因为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保证服务端正常关闭&lt;/li&gt;
&lt;li&gt;防止旧的四元组数据包影响下一次连接传输。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;正因为主动断开会进入 &lt;code&gt;TIME_WAIT&lt;/code&gt; ，此时既会白白占用端口，又会无法传输数据，经历时间还非常长，对于服务端来说是很大的负担，所以这个烂摊子尽量交给对方，尽量让对方断开连接。&lt;/p&gt;
&lt;p&gt;解决 &lt;code&gt;TIME_WAIT&lt;/code&gt;  方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;tcp_rw_reuse&lt;/code&gt; + &lt;code&gt;tcp_timestamp&lt;/code&gt; ：这样可以使得处于 &lt;code&gt;TIME_WAIT&lt;/code&gt;  套接字复用，因为开启了时间戳，新的连接不会接收时间戳过期的数据。&lt;/li&gt;
&lt;li&gt;其他方法不推荐使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;知道 SYN 攻击吗，说说你知道的防御手段&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9pbmZvLnN1cHBvcnQuaHVhd2VpLmNvbS9pbmZvLWZpbmRlci9lbmN5Y2xvcGVkaWEvemgvU1lOK0Zsb29kLmh0bWw=&#34;&gt;https://info.support.huawei.com/info-finder/encyclopedia/zh/SYN+Flood.html&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;SYN 攻击是 DDos 攻击的一种，通过程序不断发送 SYN 迅速占满服务端的 SYN 队列，使其崩溃的攻击手段。&lt;/p&gt;
&lt;p&gt;防御手段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首包丢弃：大多数 SYN 攻击都是变源的，这使得在 SYN Flood 攻击中，每个 SYN 都是首包，Anti-DDos 系统可以丢弃收到的 SYN 首包，如果对方客户端是正常的，那么基于 TCP 超时机制，一定会重传，此时 SYN 就不是首包了，可以对其进行源认证。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;源认证：Anti-DDos 系统部署在网络入口，先代替服务端发送 SYN+ACK，如果收到了客户端的 ACK，就将其 IP 加入白名单，之后一段时间都不会代替服务端对该 IP 的 SYN 进行拦截。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;源认证必须配合首包丢弃使用，不然性能瓶颈也只是从服务器转移到了 Anti-DDos 系统中。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;设置 TCP 参数也可以一定程度上防御 SYN 攻击，比如扩大半连接队列，开启 &lt;code&gt;syncookies&lt;/code&gt; 。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;TCP 的半连接队列和全连接队列了解吗？如果队列满了怎么办？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvdFJYbHExaEVycUtRTE1NTGN4b1h2Zw==&#34;&gt;https://mp.weixin.qq.com/s/tRXlq1hErqKQLMMLcxoXvg&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;半连接队列是指 SYN 队列，服务端收到 SYN 请求，就会将其加入到 SYN 队列；全连接队列是指 Accept 队列，当服务端收到客户端的 &lt;code&gt;ACK&lt;/code&gt;  就会将 SYN 队列对应节点放到 Accept 队列中。当队列满了，Linux 默认的操作是拒绝再接收 ACK。因为队列装不下了，但是有个问题就是，客户端发送了 ACK 就会进入 &lt;code&gt;ESTABLISHED&lt;/code&gt;  状态，但是实际上服务端却没有接收。&lt;/p&gt;
&lt;p&gt;Linux 中变量 &lt;code&gt;tcp_abort_on_overflow&lt;/code&gt;  为 0，就是丢掉客户端发送的数据，为 1 就会发送一个 &lt;code&gt;reset&lt;/code&gt;  包给客户端。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;所以全连接队列满了，一般解决方法就是扩大队列长度，Accept 队列长度由两个变量决定，结果式为 &lt;code&gt;len = min(backlog, somaxconn)&lt;/code&gt; 。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;半连接队列长度 &lt;code&gt;max_qlen_log&lt;/code&gt;  取决于全连接队列长度 &lt;code&gt;len&lt;/code&gt; 、变量 &lt;code&gt;max_syn_backlog&lt;/code&gt; ： &lt;code&gt;max_qlen_log = 2 * min(len, max_syn_backlog)&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;半连接队列一般不会满，当队列中剩余长度达到某个特定值时（和 &lt;code&gt;max_syn_backlog&lt;/code&gt;  有关，但是不同 Linux 版本计算方法可能不同），就不会再接收 &lt;code&gt;SYN&lt;/code&gt;  了。其实当全连接队列满了，不论半连接队列如何，都不会再接收 &lt;code&gt;SYN&lt;/code&gt;  了。&lt;/p&gt;
&lt;p&gt;半连接队列满了（假设遇到了 &lt;code&gt;SYN&lt;/code&gt;  攻击），策略有三个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;增大半连接队列长度，也就是增大那三个参数。&lt;/li&gt;
&lt;li&gt;打开 &lt;code&gt;syncookies&lt;/code&gt; ，将该变量设置为 1 即可（0-- 关闭，1-- 队列满了打开 &lt;code&gt;syncookies&lt;/code&gt; ，2-- 直接打开 &lt;code&gt;syncookies&lt;/code&gt; ）。开启该功能后，不会再丢弃 &lt;code&gt;SYN&lt;/code&gt;  包，而是服务器根据当前状态计算出一个值，放在 &lt;code&gt;SYN+ACK&lt;/code&gt;  中发出，当客户端返回 &lt;code&gt;ACK&lt;/code&gt;  报文时，取出该值校验合法性，建立连接。&lt;/li&gt;
&lt;li&gt;减少 &lt;code&gt;SYN+ACK&lt;/code&gt;  重发次数，使得处于 &lt;code&gt;SYN_REVC&lt;/code&gt;  状态的连接尽快断开。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;谈谈 TCP 相关的参数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考链接：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MveXRWN1JaU3lGWHl2UFdfbEtodjhodw==&#34;&gt;https://mp.weixin.qq.com/s/ytV7RZSyFXyvPW_lKhv8hw&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这里讲的 TCP 参数与 TCP 三次握手和四次挥手优化有关。&lt;/p&gt;
&lt;p&gt;三次握手优化角度：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端（发送方）：客户端行为有发送 &lt;code&gt;SYN&lt;/code&gt;  和 &lt;code&gt;ACK&lt;/code&gt; ，以及重发 &lt;code&gt;SYN&lt;/code&gt;  和 &lt;code&gt;ACK&lt;/code&gt; 。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tcp_syn_retries&lt;/code&gt;  参数：控制重传 &lt;code&gt;SYN&lt;/code&gt;  次数，每次超时时间为上次 2 倍，初始为 1s。&lt;strong&gt;超过次数就会断开连接&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;服务端（接收方）：服务端行为较复杂，涉及到半连接队列和全连接队列的大小以及拒绝策略
&lt;ul&gt;
&lt;li&gt;重发 &lt;code&gt;FIN+ACK&lt;/code&gt;  次数：由 &lt;code&gt;tcp_synack_retires&lt;/code&gt;  决定&lt;/li&gt;
&lt;li&gt;半连接队列：大小由 &lt;code&gt;tcp_max_syn&lt;/code&gt; 、 &lt;code&gt;backlog&lt;/code&gt; 、 &lt;code&gt;somaxconn&lt;/code&gt;  共同决定。可以通过增大这三个参数来增大半连接队列。同时 &lt;code&gt;syncookies&lt;/code&gt;  参数控制当半连接队列满了时，生成状态值校验来避免放到半连接队列中。&lt;/li&gt;
&lt;li&gt;全连接队列：大小由 &lt;code&gt;backlog&lt;/code&gt;  和 &lt;code&gt;somaxconn&lt;/code&gt;  共同决定。拒绝策略由 &lt;code&gt;tcp_abort_on_overflow&lt;/code&gt;  决定，0 表示丢弃 &lt;code&gt;ACK&lt;/code&gt; ，不让其进入全连接队列，一般用这个，还可以解决短暂的突发网络繁忙。1 表示发送 &lt;code&gt;RST&lt;/code&gt;  包使其断开连接。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;绕过三次握手：Linux 内核 3.1 版本后，出现了 &lt;code&gt;Fast Open&lt;/code&gt;  机制，通过 &lt;code&gt;Cookie&lt;/code&gt;  来绕过后面的三次握手。第一次正常三次握手，但是服务端可以在第二次握手时创建 &lt;code&gt;Cookie&lt;/code&gt;  并发送给客户端。之后就可以重用该 &lt;code&gt;TCP&lt;/code&gt;  连接，而不需要重复建立 TCP 连接。因为后续数据发送可以携带 &lt;code&gt;Cookie&lt;/code&gt; ，服务端只需要验证 &lt;code&gt;Cookie&lt;/code&gt;  即可。这种的缺点就是，如果重发，还需要重发 &lt;code&gt;Cookie&lt;/code&gt; 。该机制使用 &lt;code&gt;tcp_fastopn&lt;/code&gt; ：
&lt;ul&gt;
&lt;li&gt;0 ——  &lt;code&gt;close&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;1 ——  &lt;code&gt;Client&lt;/code&gt;  打开&lt;/li&gt;
&lt;li&gt;2 ——  &lt;code&gt;Server&lt;/code&gt;  打开&lt;/li&gt;
&lt;li&gt;3 —— 双方都打开&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;四次挥手优化角度：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主动断开方：会进入 &lt;code&gt;TIME_WAIT&lt;/code&gt;  状态，接收发送 &lt;code&gt;FIN&lt;/code&gt;  和 &lt;code&gt;ACK&lt;/code&gt; 。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tcp_max_orphan&lt;/code&gt;  参数：调用 &lt;code&gt;close&lt;/code&gt;  函数后，连接就变成了&lt;strong&gt;孤儿连接&lt;/strong&gt;，该参数限制了最大孤儿连接数量，超过直接发送 &lt;code&gt;RST&lt;/code&gt;  包断开连接。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FIN_WAIT1&lt;/code&gt;  状态优化： &lt;code&gt;tcp_orphan_retries&lt;/code&gt;  参数 —— 表示处于 &lt;code&gt;FIN_WAIT1&lt;/code&gt;  状态的 &lt;code&gt;FIN&lt;/code&gt;  重传次数，超过直接关掉连接。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FIN_WAIT2&lt;/code&gt;  状态优化： &lt;code&gt;tcp_fin_timeout&lt;/code&gt;  参数：表示孤儿连接等待 &lt;code&gt;FIN&lt;/code&gt;  的最长时间，默认 60s。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TIME_WAIT&lt;/code&gt;  状态优化：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tcp_max_tw_buckets&lt;/code&gt;  参数：如果处于 &lt;code&gt;TIME_WAIT&lt;/code&gt;  连接超过该参数，之后的连接不再进入该状态。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tcp_tw_reuse&lt;/code&gt;  参数：开启后可以复用处于 &lt;code&gt;TIME_WAIT&lt;/code&gt;  状态的连接，需要配合时间戳使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;被动断开方：
&lt;ul&gt;
&lt;li&gt;还是借助 &lt;code&gt;tcp_orphan_retires&lt;/code&gt;  参数限定 &lt;code&gt;FIN&lt;/code&gt;  重传次数。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;小结：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;三次握手参数： &lt;code&gt;tcp_syn_retries&lt;/code&gt; 、 &lt;code&gt;somaxconn&lt;/code&gt; 、 &lt;code&gt;backlog&lt;/code&gt; 、 &lt;code&gt;tcp_max_syn&lt;/code&gt; 、 &lt;code&gt;syncookies&lt;/code&gt; 、 &lt;code&gt;tcp_abort_on_overflow&lt;/code&gt; 、 &lt;code&gt;tcp_fastopn&lt;/code&gt; 。&lt;/li&gt;
&lt;li&gt;四次挥手参数： &lt;code&gt;tcp_max_orphan&lt;/code&gt; 、 &lt;code&gt;tcp_orphan_retries&lt;/code&gt; 、 &lt;code&gt;tcp_fin_timeout&lt;/code&gt; 、 &lt;code&gt;tcp_max_tw_buckets&lt;/code&gt; 、 &lt;code&gt;tcp_tw_reuse&lt;/code&gt; 。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;聊聊 TCP 的可靠传输机制，比如重传、拥塞、流量控制等&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;重传机制&lt;/strong&gt;： 接收方回复 ACK 用于提醒发送方应该发那个数据包，当出现数据包丢失，接收方需要重传，分为超时重传和快速重传&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;超时重传：接收方拿不到 3 这个数据包，就不发 3 的 ACK，发送方等待 3 这个 ACK 超时，再重传，一种是只重传 3（节省带宽，慢），另一种是 3，4，5（快，浪费带宽）等都重传。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;快速重传：发送方连续三次接收到同一个 ACK，则重传对应的数据报。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其实重传都面临一个选择：只重传这一个还是重传后边所有数据报。这就引出&lt;strong&gt; SACK&lt;/strong&gt; 机制，接收方回复 SACK，SACK 会汇报收到的数据碎片，这个协议需要两边都支持。但是 SACK 并不能替代 ACK，&lt;strong&gt;接收方有权把已经报给发送端 SACK 里的数据给丢了&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SACK&lt;/strong&gt; 有一个严重的问题，Linux 代码中，使用一个 &lt;code&gt;sk_buff&lt;/code&gt;  的数据结构，简称 &lt;code&gt;SKB&lt;/code&gt; ，用于存储&lt;strong&gt;发送、接收&lt;/strong&gt;队列等，还有一个结构体为 &lt;code&gt;skb_cb&lt;/code&gt;  用于控制缓存，记录各种&lt;strong&gt; TCP packet&lt;/strong&gt; 的各种信息，如小报文的数量 &lt;code&gt;tcp_gso_segs&lt;/code&gt; ，无符号两字节，最多表示 64K，SKB 会将小报文段分片累积成大报文段再发送，但是内部最多维护 17 个分片队列，每个队列最大 32KB，如果有恶意攻击者将 &lt;code&gt;mss&lt;/code&gt;  设置为 8，则每个小报文段大小为 8B。&lt;strong&gt;SACK&lt;/strong&gt; 机制会将许多 &lt;code&gt;SKB&lt;/code&gt;  合并填满一个 &lt;code&gt;SKB&lt;/code&gt; ，那么就可能出现： &lt;code&gt;17 * 32 * 1024 / 8 &amp;gt; 64K&lt;/code&gt;  导致 &lt;code&gt;tcp_gso_segs&lt;/code&gt;  溢出，进入 &lt;code&gt;BUG_ON&lt;/code&gt;  函数使得服务器拒绝远程连接。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;滑动窗口&lt;/strong&gt;：发送方和接收方都有窗口，接收方的滑动窗口可以使发送方根据接收方的接收能力来发送数据。确认机制为&lt;strong&gt;累计确认 / 累计应答&lt;/strong&gt;，假设收到序列号为 100 的 ACK，说明 100 以前的数据都收到了。&lt;/p&gt;
&lt;p&gt;如果接收方的窗口为 0 了，也会将发送方的窗口设为 0（让发送方知道接收方窗口大小，这是根据 TCP 首部有个字段 win 可以控制窗口大小），此时不再发送数据，直到接收方窗口恢复，此时发送一个通知消息给发送方，并等待数据。如果这个通知消息因为网络拥塞丢失了，就会导致：接收方一直等待数据，发送方一直等待通知的死锁状况。所以一旦发送方窗口被置为 0，就会每隔一段时间发送探测报文，询问接收方窗口大小。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Silly Window Syndrome&lt;/strong&gt; 是一种现象，会对小的 window size 做出响应，为了避免对小的 window size 做出响应，直到有足够大的 window size 再响应，如果窗口太小，发送出去的数据甚至没有 &lt;code&gt;MSS&lt;/code&gt;  高，就会先累积再发送。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;拥塞处理&lt;/strong&gt;：名词： &lt;code&gt;ssthresh&lt;/code&gt;  是慢启动阈值， &lt;code&gt;cwnd&lt;/code&gt;  为拥塞窗口大小。&lt;/p&gt;
&lt;p&gt;三个状态，分别是慢启动，拥塞避免和快速恢复。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;慢启动&lt;/strong&gt;： &lt;code&gt;cwnd&lt;/code&gt; （拥塞窗口）一开始为 &lt;code&gt;1MSS&lt;/code&gt; ，每过 1 个 &lt;code&gt;RTT&lt;/code&gt;  就二倍上升（本质是每收到一个 &lt;code&gt;ACK&lt;/code&gt;  就 &lt;code&gt;cwmd++&lt;/code&gt; ），如果&lt;strong&gt;超时&lt;/strong&gt;， &lt;code&gt;ssthresh=cwnd/2&lt;/code&gt; ，并且 &lt;code&gt;cwnd=1&lt;/code&gt;  重新慢启动。如果之后 &lt;code&gt;cwnd &amp;gt;=  ssthresh&lt;/code&gt;  就进入&lt;strong&gt;拥塞避免&lt;/strong&gt;。如果触发快速重传，就进入&lt;strong&gt;快速恢复&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;拥塞避免&lt;/strong&gt;：每一个 &lt;code&gt;RTT&lt;/code&gt;  就 &lt;code&gt;cwnd++&lt;/code&gt; ，如果超时，设置 &lt;code&gt;ssthresh=cwnd/2, cwnd = 1&lt;/code&gt; ，进入慢启动。如果连续三次收到同一个 &lt;code&gt;Ack&lt;/code&gt; ，设置参数为 &lt;code&gt;ssthresh=cwnd/2, cwnd = ssthresh + 3&lt;/code&gt; 。进入&lt;strong&gt;快速恢复&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;快速恢复&lt;/strong&gt;：（进入快速恢复说明窗口长度太小了）如果超时，同样操作，进入慢启动；每次收到一个冗余 &lt;code&gt;ACK&lt;/code&gt; ， &lt;code&gt;cwnd++&lt;/code&gt; ，如果收到新 &lt;code&gt;ACK&lt;/code&gt; ，进入&lt;strong&gt;拥塞避免&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;这里的 &lt;code&gt;RTT&lt;/code&gt;  是指一个窗口的数据全部发送出去，又全部收到 &lt;code&gt;ACK&lt;/code&gt;  的时间，而不是某一个报文的往返时间&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;TCP 粘包和拆包问题&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；或者是，接收数据端的应用层没有及时读取接收缓冲区的数据，将发生粘包。&lt;/li&gt;
&lt;li&gt;要发送的数据大于 TCP 发送缓冲区剩余空间大小或者大于 MSS，将会发生拆包；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;解决方案为，发送端将数据包封装为固定长度，在数据尾部增加特殊字符，将数据分为两部分，头部和内容提，头部结构大小固定，且有一个字段声明内容体的大小。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Nagle 算法与延迟确认&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果发送方疯狂地向接收方发送很小的数据包，比如一次就发送 1 个字节，那么显然会有问题。每次都会为这种小数据包加上头部并且发过去，比较浪费网络带宽。&lt;/p&gt;
&lt;p&gt;Nagle 算法是一种优化 TCP 协议的算法，它的主要作用是减少网络拥塞和提高网络吞吐量。当我们发送小数据包时，Nagle 算法会将它们缓存起来，直到缓存区中的数据量达到一定大小或者一定时间后再一次性发送出去。这样可以减少网络传输的次数，从而提高网络吞吐量。但是，当我们发送大数据包时，Nagle 算法会立即发送出去，以避免数据包的延迟。&lt;/p&gt;
&lt;p&gt;而延迟确认则是接收方收到数据包后，如果暂时没有数据要发给对端，它可以等一小段时间，再确认（Linux 上默认是 40ms）。如果这段时间刚好有数据要传给对端，ACK 就随着数据传输，而不需要单独发送一次 ACK。如果超过时间还没有数据要发送，也发送 ACK，避免对端以为丢包。一般情况下，&lt;strong&gt;Nagle 算法和延迟确认&lt;/strong&gt;不能一起使用，Nagle 算法意味着延迟发，&lt;strong&gt;延迟确认&lt;/strong&gt;意味着延迟接收，会造成更大的延迟，会产生性能问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;DNS 劫持和 DNS 污染&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;DNS 劫持&lt;/strong&gt;：劫持了 DNS 服务器，通过某些手段取得某域名的解析记录控制权，进而修改此域名的解析结果，导致对该域名的访问由原 IP 地址转入到修改后的指定 IP。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DNS 污染&lt;/strong&gt;：通过对 UDP 端口 53 上的 DNS 查询进行入侵检测，一经发现与关键词相匹配的请求则立即伪装成目标域名的解析服务器（NS，Name Server）给查询者返回虚假结果。很难靠个人设置解决，使用 VPN 是一个方法&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;聊聊 IP 协议，它和 MAC 地址有什么区别，IPV4 和 IPV6 呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;IP 协议用于唯一标识网络设备，属于网络层协议，传输层将数据包传到网络层后，会为数据加上 IP 首部。 &lt;code&gt;MAC&lt;/code&gt;  属于链路层，用于标识下一跳的网络设备的物理地址，数据从源主机到目的主机的过程中， &lt;code&gt;MAC&lt;/code&gt;  首部每经过一个路由器都会变换，而 IP 地址不会变换。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IPv4&lt;/code&gt;  地址由 32 位组成，以前会根据前几位将其分为 &lt;code&gt;ABCDE&lt;/code&gt;  类地址，但是分类地址的局限性太多，比如 C 类 IP 数量太少，而 A 类 IP 数量有太多，所以采用了无分类 IP 地址，通过子网掩码和 IP 地址做 ** &lt;code&gt;&amp;amp;&lt;/code&gt;  运算&lt;strong&gt;来确定&lt;/strong&gt;网络号、子网号 **。在路由控制中，目的地址与路由表中的子网掩码运算并比较网络号，从而进行路由转发。&lt;/p&gt;
&lt;p&gt;IP 协议因为不能重组分片数据，所以分片会导致严重的性能损耗，一个分片丢失了，就要重发整个 IP 数据报，所以通过引入 &lt;code&gt;MSS&lt;/code&gt;  将分片操作交给 &lt;code&gt;TCP&lt;/code&gt;  处理。&lt;/p&gt;
&lt;p&gt;IPv6 相对于 IPv4 的改进：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取消了首部校验和字段：因为数据链路层和传输层都会校验&lt;/li&gt;
&lt;li&gt;取消分片 / 重组相关字段，这种操作只允许源 / 目标主机。&lt;/li&gt;
&lt;li&gt;使用了 128 位，16 进制，极大扩充了 IP 数量&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;WebSocket 和 Socket 的区别&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Socket 其实就是等于&lt;strong&gt; IP 地址 + 端口 + 协议&lt;/strong&gt;，是一种传输层协议，它提供了一种在网络上进行双向通信的方式。Socket 可以用于不同的网络协议，如 TCP 和 UDP。WebSocket 是一种应用层协议，它建立在 HTTP 协议之上。WebSocket 提供了一种在客户端和服务器之间进行双向通信的方式，而不需要像 HTTP 那样每次请求都要建立一个新的连接。WebSocket 可以在客户端和服务器之间传输任意类型的数据，而不仅仅是文本数据。&lt;/p&gt;
&lt;p&gt;WebSocket 和 Socket 的主要区别在于它们的应用场景和通信方式。Socket 通常用于客户端和服务器之间的通信，而 WebSocket 通常用于实时通信，如在线聊天和游戏等。WebSocket 使用 HTTP 协议进行握手，然后建立一个持久连接，而 Socket 需要在每次通信之前都要建立一个新的连接。&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
