{
    "version": "https://jsonfeed.org/version/1",
    "title": "慕青の迷途 • All posts by \"八股文\" tag",
    "description": "时雨病重症患者",
    "home_page_url": "https://cecilia.cool",
    "items": [
        {
            "id": "https://cecilia.cool/2023/03/05/%E5%85%AB%E8%82%A1%E6%96%87/Java%E9%9B%86%E5%90%88/",
            "url": "https://cecilia.cool/2023/03/05/%E5%85%AB%E8%82%A1%E6%96%87/Java%E9%9B%86%E5%90%88/",
            "title": "Java集合",
            "date_published": "2023-03-05T02:02:30.000Z",
            "content_html": "<p>本文涉及到 Java 集合部分，也包括线程安全的集合，还是以面试题的形式记录。</p>\n<blockquote>\n<p>1. <code>ArrayList</code>  和 <code>LinkedList</code>  遍历谁更快？</p>\n</blockquote>\n<p><code>ArrayList</code>  更快， <code>ArrayList</code>  的优势就是内存连续，如果遍历 <code>LinkedList</code> ，随机 IO 可能更多一些</p>\n<blockquote>\n<p>2. 谈谈你对 <code>ArrayList</code>  的理解</p>\n</blockquote>\n<p>从我学习程度来看， <code>ArrayList</code>  需要注意的是：</p>\n<ul>\n<li>线程不安全，如果要保证安全，可以使用 <code>Vector</code>  或者使用 <code>Collections.synchronizedList(xx)</code> ，前者在每个操作方法上都加了 <code>synchronized</code>  关键字，后者内部会维护一个排他锁，每次对集合操作时，都需要先竞争锁。</li>\n<li>迭代器的 <code>fail-fast</code>  机制：这其实是每个实现了 <code>iterator</code>  集合都需要注意的地方，每次对数组进行增删，都会使得 <code>modCount++</code> ，而迭代器的 <code>next</code>  函数会检测 <code>modCount</code>  是否和最开始的自己保存的 <code>modCount</code>  相同，也就是检测在迭代的过程中数组是否发生了改变，<strong>因为这可能使得迭代过程中漏了某些元素或者重复遍历某些元素</strong>。</li>\n<li><code>ArrayList</code>  内部是使用 <code>Object</code>  数组 -- <code>elementData</code> ，但是该变量没有被 <code>private</code>  修饰，代码注释写的是方便内部类更快的访问该属性，如果被 <code>private</code>  修饰，那么同样的代码反编译后的字节码文件更复杂一些。</li>\n<li>扩容时，是 1.5 倍增长，而 <code>Vector</code>  扩容默认两倍扩容。</li>\n</ul>\n<blockquote>\n<p>3. <code>HashMap</code>  了解吗？1.7 版本和 1.8 版本都什么区别</p>\n</blockquote>\n<p><code>JDK1.7</code>  的 <code>HashMap</code>  使用的是数组桶加链表，如果链表过长，那么时间复杂度会退化为 O (n)，而 1.8 使用的引入了红黑树，当链表节点为 8 时，就转为红黑树。至于为什么是 8，估计也是个统计概率值。</p>\n<p><code>1.7</code>  节点插入时使用的是头插法，而 1.8 使用的是尾插法，头插在并发环境下容易出现环导致死循环，具体形成原因我并没有仔细研究，因为我认为 <code>HashMap</code>  本身就是线程不安全的，无论是头插还是尾插，在并发环境下都不能使用 <code>HashMap</code> ，曾经也有人向社区报告 <code>bug</code>  说 1.7 的 <code>HashMap</code>  尾插会在并发环境下出现死循环，但是社区并没有管，而是回复 “ <code>HashMap</code>  本来就不是给你在并发环境用的，想要安全请使用 <code>ConcurrentHashMap</code> ”。</p>\n<blockquote>\n<p>4. <code>HashMap</code>  扩容机制了解过吗，为什么容量大小必须是 2 的指数</p>\n</blockquote>\n<p><code>HashMap</code>  的容量大小默认是 16，阿里巴巴开发规范插件提示在初始化 <code>HashMap</code>  时尽量指定容量大小（预计存储个数 / 负载因子 + 1），因为没有指定可能会导致多次扩容，这个涉及到重建 <code>Hash</code>  表，链表分拆的操作，比较耗时。如果构造函数传入的容量不是 2 的指数，那么会将容量设置为既是 2 的指数，又是大于传入参数的最小数。</p>\n<p>至于为什么是 2 的指数，涉及 <code>hash</code>  公式，也就是 <code>index = hash &amp; (len - 1)</code> ，这个公式其实就相当于用长度取模 <code>index = hash % len</code> ，只不过位运算快很多。扩容机制为两倍扩容，公式为 <code>newCap = 2 * oldCap</code> ，我们假设下标为 <code>i</code>  的那一部分，这个部分的链表的节点都满足 <code>hash / len = y ... i</code> ，也就是说，我们假设商为 <code>y</code> ，那么当商为奇数时（ <code>hash &amp; oldCap == 0</code> ），扩容后再使用 <code>hash</code>  公式得到的结果就是 <code>i+n</code> ，如果商为偶数的话，扩容后再 <code>hash</code>  的结果还是 <code>i</code> 。这就使得每次扩容，都将现有的链表拆为两部分，一部分留在当前下标，另一部分转移到扩容后的 <code>i+n</code>  处，这种机制使用扩容时逻辑简单，操作迅速，还使得数组中节点分布均匀，不会出现那种节点都分布在前半部分或者后半部分。</p>\n<blockquote>\n<p>5. 为什么重写 <code>equals</code>  方法的同时建议重写 <code>hashCode方法</code> ，能用 <code>HashMap</code>  举个例子吗？</p>\n</blockquote>\n<p>我们假设一个类为 <code>People</code> ，只有一个属性 <code>name</code> ，那么现实情况下，两个对象相等，要么他们内存地址相同，要么 <code>equals</code>  比较后相同，这里也就是 <code>name</code>  相同。如果不重写 <code>hashCode</code>  方法，也就是使用 <code>Object</code>  内置的方法。现在有两个内存地址不同的 <code>People</code>  对象， <code>name</code>  相同使得 <code>equals</code>  相同，但是 <code>hashCode</code>  却不相同，那么当这两个对象作为 <code>Key</code>  加入到 <code>HashMap</code>  时，我们希望的是后加入的对象会覆盖前面加入的，因为两个对象是相同的，但是因为 <code>hashCode</code>  不同，他们两个甚至连映射出来的数组下标都不同，是无法覆盖的。这也就导致 <code>HashMap</code>  中有两个相同的 <code>key</code> ，这明显不符合哈希表的定义。</p>\n<p>再来看 <code>HashMap</code>  的源码，为了实现覆盖操作，首先就要使得 <code>equals</code>  相同的对象 <code>hashCode</code>  也相同才一定能映射到同样的下标，然后顺着链表向下查找，如果 <code>HashCode</code>  相同，同时 <code>equals</code>  也相同就会覆盖，反之如果遍历了整个链表都没有这样的节点，就算做新增节点，尾插到链表中。</p>\n<blockquote>\n<p>6. 说说 <code>HashMap</code>  与 <code>HashTable</code>  的区别</p>\n</blockquote>\n<ul>\n<li>并发： <code>HashTable</code>  用于并发环境，通过在方法上加入 <code>synchronized</code>  关键字保证线程安全，但是并行度太低了，所以大多数都使用 <code>ConcurrentHashMap</code> 。而 <code>HashMap</code>  是线程不安全的。</li>\n<li>存储： <code>HashTable</code>  键值对不允许存储 <code>null</code> ，而 <code>HashMap</code>  却可以， <code>HashTable</code>  源码中会先判断 <code>value</code>  是不是 <code>null</code> ，从而抛出空指针异常，并且会直接调用 <code>key</code>  的 <code>hashCode</code>  方法，计算比较粗暴，而 <code>HashMap</code>  统一指定 <code>key==null</code>  时 <code>hashCode</code>  为 0，至于 <code>value</code>  是否为 <code>null</code>  完全不重要，因为插入删除过程都不会涉及到 <code>value</code> ，只会比较 <code>key</code> 。</li>\n<li>迭代： <code>HashTable</code>  有两个迭代器， <code>Enumeration</code>  使用的是安全失败机制（ <code>fail-safe</code> ），而 <code>Iterator</code>  是快速失败机制。 <code>HashMap</code>  使用的是快速失败机制。</li>\n</ul>\n<blockquote>\n<p>7. 刚才提到 <code>ConcurrentHashMap</code> ，你知道什么？</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvTXk0UF9CQlhEbkFHWDFnaDYzMFpLdw==\">https://mp.weixin.qq.com/s/My4P_BBXDnAGX1gh630ZKw</span></p>\n<p>这个也要分 <code>1.7</code>  和 <code>1.8</code>  两个版本：</p>\n<ul>\n<li><code>1.7</code>  使用的是数组桶 + 链表，分段，段数决定并行度。通俗来讲， <code>1.7</code>  版本维护了一个数组，数组中每个元素都是一个 <code>HashMap</code> ，上锁就是对每个段上锁。所以并行度并不高</li>\n<li><code>1.8</code>  使用的是数组桶 + 链表（升级红黑树），同时锁的粒度更小了，使用 <code>CAS+synchronized</code>  来实现并发安全。维护的数组和 <code>HashMap</code>  的数组是一致的，只不过每次上锁都是对要修改的下标单个元素进行上锁。由于 <code>Synchronized</code>  的性能采用锁升级的方式优化后， <code>ConcurrentHashMap</code>  的性能也随之上升。</li>\n</ul>\n<p>至于 <code>CAS</code>  操作，是对数组元素进行修改，也就是<strong>链表的表头</strong>。</p>\n<p>只要上了锁，保证了线程安全，其他的都和 <code>HashMap</code>  没有太多区别，也就有些细节不同，比如 <code>HashMap</code>  再加入一个键值对就要扩容了，它会先插入再扩容，而 <code>ConcurrenHashMap</code>  是先扩容再插入。</p>\n",
            "tags": [
                "八股文"
            ]
        },
        {
            "id": "https://cecilia.cool/2023/02/27/%E5%85%AB%E8%82%A1%E6%96%87/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/",
            "url": "https://cecilia.cool/2023/02/27/%E5%85%AB%E8%82%A1%E6%96%87/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/",
            "title": "计算机网络",
            "date_published": "2023-02-27T09:09:36.000Z",
            "content_html": "<p>本文积累了作者在准备面试时学习的<strong>计算机网络</strong>的知识与问题，作为科班出身，408 这些科目的重要性不必多说，能直接检验出你作为科班选手的水准。</p>\n<p>本 tag 的文章的问题都是本人先学习后，凭记忆写下的，相当于二次复习（复盘）了，这样有助于加深印象。</p>\n<blockquote>\n<p>1. 键入网址后依次发生了什么？</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvSTZCTHdiSXBmR0VKbnhqRGNQWGMxQQ==\">https://mp.weixin.qq.com/s/I6BLwbIpfGEJnxjDcPXc1A</span></p>\n<ul>\n<li>浏览器解析 URL 生成 Http 请求。</li>\n<li><strong>发送 Http 请求前，会将域名解析为 IP 地址</strong>，会先查询浏览器缓存、系统缓存、本机 <code>hosts</code>  文件，如果没有，就会发送请求到本地域名服务器，通过本地域名服务器分别访问根域名服务器、顶级域名服务器、权威域名服务器，最终拿到域名映射的 IP 地址，并且缓存起来。</li>\n<li><strong>建立 TCP 连接，三次握手</strong>。三次握手是为了双方确定对方具有发送和接收数据的能力，所以两次握手不行</li>\n<li><strong>增加 TCP 头部</strong>。如果 Http 数据太长，超过了 MSS（网络层数据大小），就需要将其切分再每个加上 TCP 头部。TCP 头部包含了源端口，目的端口，校验和，序号等信息，最后交给 IP 模块处理。</li>\n<li><strong>加上 IP 头部</strong>。IP 头部包含了源地址和目的地址，如果主机有多个网卡，会根据路由表规则来选择网卡，其实就是目的地址与网卡的掩码做<strong>与运算</strong>从而来选择，如果都不匹配，就会走默认网卡 0.0.0.0。</li>\n<li><strong>加上 MAC 头部</strong>。通过 ARP 协议来获取目的地址的 MAC 地址，如果 ARP 缓存有，就直接用，如果没有，就在以太网中广播目的地址从而得到响应拿到对应的 MAC 地址。</li>\n<li><strong>将给网卡，将包转为电信号，通过网线发送出去</strong>。</li>\n<li><strong>交换机拿到包，通过 MAC 表将数据从对应端口发送出去</strong>，如果表中没有对应映射，就对局域网所有主机发送。</li>\n<li><strong>路由器拿到包并根据 IP 地址进行转发</strong>。MAC 头部作用就是将包送到路由器，然后 MAC 头部就会被丢弃。路由器根据路由表决定下一跳（下一跳的 IP）。通过 ARP 协议拿到下一跳的 MAC 地址，重新发送。整体传输过程只有 MAC 地址在不断变化，因为包需要不断在以太网中传输。</li>\n<li>服务器收到请求，回复 ACK 和 Http 响应。浏览器得到响应，再请求 html 中的 js，css 资源。浏览器再解析渲染，呈现网页。</li>\n</ul>\n<blockquote>\n<p>2. 谈谈 http 协议</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvQUsxUGI5cngwcTVIZjhkcTZITk9odw==\">https://mp.weixin.qq.com/s/AK1Pb9rx0q5Hf8dq6HNOhw</span></p>\n<p>http 协议是超文本传输协议，一开始用于传输 html、css、js 等资源文件，后来也可以传输图片、视频、音频等。http1.0 是无状态的，每个 http 请求都必须重新建立 TCP 连接，这导致开销较大。http1.1 通过 <code>Cookie</code>  来管理状态，同时实现了持久化连接。</p>\n<p>http 请求由：请求行、消息头、数据组成。请求行包括请求方法、<strong>URI</strong>、协议版本。</p>\n<p>请求方法包括 GET（表单）、POST（实体）、DELETE（删除文件）、PUT（文件）、TRACE 等组成。</p>\n<p>状态码含义分别是：</p>\n<ul>\n<li>1xx：表示请求正在处理</li>\n<li>2xx：表示请求成功处理</li>\n<li>3xx：表示重定向</li>\n<li>4xx：表示客户端错误，请求不合法</li>\n<li>5xx：表示服务器错误，不能处理合法请求</li>\n</ul>\n<blockquote>\n<p>3. 谈谈 https 协议</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvMjFKYVh3ZGZTakl0ajVTZ093aGFwZw==\">https://mp.weixin.qq.com/s/21JaXwdfSjItj5SgOwhapg</span></p>\n<p>数据传输使用的仍然是 http 协议，只不过使用了 SSL 对数据进行了加密，保证了数据传输的安全。</p>\n<p>其过程为：</p>\n<ul>\n<li>客户端发送 https 请求，服务端响应<strong> CA 证书和公钥</strong>。（需要注意，是<strong>证书里面附带了公钥</strong>）</li>\n<li>客户端校验 CA 证书合法性，生成随机密钥 key，并使用<strong>公钥</strong>对 key 加密，再发送给服务端。</li>\n<li>服务端收到后，使用私钥对可 key 解密，拿到真正的 key，双方之后的数据传输就用该 key 进行<strong>对称加密传输</strong>。</li>\n</ul>\n<p>上述过程，如果没有 CA 证书，那么中间人攻击可以这样：在第一步将公钥换成自己的公钥 1，这样在第二步对客户端产生的 key 使用自己的私钥 1 解密从而拿到 key。最后再将 key 使用最开始服务端发送的公钥进行加密发送给服务端，这样 MITM（中间人攻击）照样可以完成。</p>\n<p>所以需要第三方的公信认证，CA 机构有一对公钥 / 私钥，公钥是对外界公开的，而私钥必须严格保密。当服务端将<strong> CA 证书 + 服务端公钥</strong>发送给客户端时， 会先将证书的数据（包括服务端公钥）进行哈希，得到哈希值<strong> H</strong>，再用私钥将 H 加密，最后客户端（浏览器）拿到证书后，会使用系统 / 浏览器内置的 CA 公钥对 H 进行解密得到 H，再自己通过证书指定的哈希算法对数据进行哈希得到<strong> H'</strong>，比较<strong> H==H'</strong>。</p>\n<p>私钥和公钥可以互相加密解密，非不是私钥只能解密。上述过程，假设有中间人换了证书中的服务端公钥，也会因为不知道私钥而无法加密哈希值导致客户端会检测出来。所以 CA 机构应该严格保密私钥，如果泄露，就会失去公信力。</p>\n<p>如果整个 https 通信全部用非对称加密确实可以，双方各拿一对公钥 / 私钥，然后交换公钥进行通信。至于为什么本质还是要使用对称加密，是因为非对称加密太耗时间了，仅用于传输 key 即可。</p>\n<blockquote>\n<p>4. 用过 ping 吗，说说原理</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvM0tGMEl4THVtOEVPdGNGMFpOSWlQQQ==\">https://mp.weixin.qq.com/s/3KF0IxLum8EOtcF0ZNIiPA</span></p>\n<p><code>ping</code>  实现原理依托于 <code>ICMP</code>  协议。该协议是互联网控制报文协议，用于报告网络错误、传送报文运输情况等。 <code>ICMP</code>  报文被封装到 <code>IP</code>  数据包里面。ping 使用的两种 <code>ICMP</code>  数据包是<strong>回送请求</strong>和<strong>回送响应</strong>。</p>\n<p>假设主机 A 对主机 B 进行了 ping 操作，那么主机 A 会封装 ** <code>ICMP</code>  回送请求 **，此时会记录请求产生的时间，并将其封装到 IP 数据包中，再加上 MAC 头部，最后发送出去。没有缓存目的 MAC 地址，先通过 ARP 协议获取。</p>\n<p>主机 B 收到报文后，逐步拆除 MAC 和 IP 头部，经过地址检验后，将有用的信息提取交给 ICMP 协议，再发送 ** <code>ICMP</code>  回送响应 **。主机 A 收到回送响应后，用当前时间减去 <code>ICMP</code>  数据包发送时间，就可以得到 <code>RTT</code> 。</p>\n<p>同时， <code>ICMP</code>  还维护了一个 <code>TTL</code> ，每次数据包经过一个路由器，就会 - 1，直到为 0 被丢弃，TTL 就可以检测出两个主机之间经过多少跳。</p>\n<p><code>tracert</code>  也是借助 <code>ICMP</code>  协议实现的。</p>\n<blockquote>\n<p>5. 聊聊 TCP 三次握手和四次挥手</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvclgzQV9GQTE5bjRwSTlIaWNJRXNYZw==\">https://mp.weixin.qq.com/s/rX3A_FA19n4pI9HicIEsXg</span></p>\n<p>TCP<strong> 三次握手</strong>：</p>\n<ul>\n<li>\n<p>确认双方都有发送和接收数据的能力。</p>\n</li>\n<li>\n<p>防止旧连接覆盖新连接。客户端知道自己此时应该建立哪个连接，但是网络传输过程复杂，很可能旧的连接 SYN 比新的 SYN 后到，到底建立哪个连接服务端是不知道的，所以必须有第三次握手，让客户端确认到底建立哪个连接。</p>\n</li>\n<li>\n<p>防止浪费资源。两次握手中，服务端不知道自己的 <code>ACK+SYN</code>  是否被客户端收到，这会导致重复发送 <code>SYN+ACK</code> ，建立很多个无用的连接。</p>\n</li>\n<li>\n<p>同步初始化序列号。同步序列号能够防止接收端接收的数据乱序。</p>\n</li>\n</ul>\n<p>总的来说，第三次握手是必要的，<strong>必须由客户端确认建立连接的各种状态信息的正确性</strong>。值得一提的是，第三次握手，发送方可以顺带发送数据。</p>\n<p>TCP<strong> 四次挥手</strong>：</p>\n<p>重点：主动放弃连接的一方会进入 <code>Time_Wait</code>  状态，在 Linux 中，会等待 2MSL（60 秒）。</p>\n<p>四次挥手的过程为（假设客户端主动断开连接）：</p>\n<ol>\n<li>客户端发送 <code>Fin</code>  表示自己断开连接，不再发送数据，但是可以接收数据，进入 <code>FIN_WAIT_1</code>  状态。</li>\n<li>服务端收到 <code>Fin</code> ，发送 <code>ACK</code> ，表示自己收到断开请求，需要处理剩下的数据，进入 <code>CLOSED_WAIT</code> 。</li>\n<li>服务端处理完数据，发送 <code>Fin</code> ，进入 <code>LAST_ACK</code>  状态。</li>\n<li>客户端收到 <code>Fin</code> ，发送 <code>ACK</code> ，进入 <code>TIME_WAIT</code>  状态，等待 <code>2MSL</code> ，最后进入 <code>CLOSED</code>  状态。</li>\n</ol>\n<p>正是因为服务端需要处理剩下数据，所以是四次挥手，同样，如果省去最后一次挥手，那么服务端就会一直处于 <code>LAST_ACK</code>  状态，当客户端想建立新的连接，发送 <code>SYN</code> ，服务端就会回复 <code>RST</code> ，建立连接的过程会终止。</p>\n<blockquote>\n<p>6. 为什么四次挥手中要有 <code>TIME_WAIT</code>  状态以及为什么要等 2MSL？</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvclgzQV9GQTE5bjRwSTlIaWNJRXNYZw==\">https://mp.weixin.qq.com/s/rX3A_FA19n4pI9HicIEsXg</span></p>\n<p>我们这里默认主动断开连接的是客户端。首先，主动断开连接的那一方才会进入 <code>TIME_WAIT</code> ，这个时间是 2MSL，在 Linux 中为 60s，而且这个时间是固定的，也就是在内核代码中写死了，无法修改。</p>\n<p><code>TIME_WAIT</code>  的出现能够保证被动断开连接方（服务端）可以正常的关闭，从 <code>LAST_ACK</code>  进入 <code>CLOSED</code>  状态。</p>\n<p>MSL 是数据包在网络传输中存活的最长时间， <code>TIME_WAIT</code>  设置为 2MSL，比较合理的解释为：如果服务端没有没有 ACK，超时重传 <code>FIN</code>  后再接收 <code>ACK</code>  的时间在 2MSL 之内。<strong>当客户端重新接收到 <code>FIN</code>  时，会重置 2MSL 时间</strong>。同时网络连接中的旧数据包在 2MSL 中能够被清理干净，如果客户端当前端口重新建立连接，不会有旧的数据传到当前端口，造成数据混乱。</p>\n<p><code>TIME_WAIT</code>  出现的原因为：</p>\n<ul>\n<li>保证服务端正常关闭</li>\n<li>防止旧的四元组数据包影响下一次连接传输。</li>\n</ul>\n<p>正因为主动断开会进入 <code>TIME_WAIT</code> ，此时既会白白占用端口，又会无法传输数据，经历时间还非常长，对于服务端来说是很大的负担，所以这个烂摊子尽量交给对方，尽量让对方断开连接。</p>\n<p>解决 <code>TIME_WAIT</code>  方法：</p>\n<ul>\n<li>使用 <code>tcp_rw_reuse</code> + <code>tcp_timestamp</code> ：这样可以使得处于 <code>TIME_WAIT</code>  套接字复用，因为开启了时间戳，新的连接不会接收时间戳过期的数据。</li>\n<li>其他方法不推荐使用。</li>\n</ul>\n<blockquote>\n<p>7. 知道 SYN 攻击吗，说说你知道的防御手段</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9pbmZvLnN1cHBvcnQuaHVhd2VpLmNvbS9pbmZvLWZpbmRlci9lbmN5Y2xvcGVkaWEvemgvU1lOK0Zsb29kLmh0bWw=\">https://info.support.huawei.com/info-finder/encyclopedia/zh/SYN+Flood.html</span></p>\n<p>SYN 攻击是 DDos 攻击的一种，通过程序不断发送 SYN 迅速占满服务端的 SYN 队列，使其崩溃的攻击手段。</p>\n<p>防御手段：</p>\n<ul>\n<li>\n<p>首包丢弃：大多数 SYN 攻击都是变源的，这使得在 SYN Flood 攻击中，每个 SYN 都是首包，Anti-DDos 系统可以丢弃收到的 SYN 首包，如果对方客户端是正常的，那么基于 TCP 超时机制，一定会重传，此时 SYN 就不是首包了，可以对其进行源认证。</p>\n</li>\n<li>\n<p>源认证：Anti-DDos 系统部署在网络入口，先代替服务端发送 SYN+ACK，如果收到了客户端的 ACK，就将其 IP 加入白名单，之后一段时间都不会代替服务端对该 IP 的 SYN 进行拦截。</p>\n</li>\n</ul>\n<p>源认证必须配合首包丢弃使用，不然性能瓶颈也只是从服务器转移到了 Anti-DDos 系统中。</p>\n<ul>\n<li>设置 TCP 参数也可以一定程度上防御 SYN 攻击，比如扩大半连接队列，开启 <code>syncookies</code> 。</li>\n</ul>\n<blockquote>\n<p>8.TCP 的半连接队列和全连接队列了解吗？如果队列满了怎么办？</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvdFJYbHExaEVycUtRTE1NTGN4b1h2Zw==\">https://mp.weixin.qq.com/s/tRXlq1hErqKQLMMLcxoXvg</span></p>\n<p>半连接队列是指 SYN 队列，服务端收到 SYN 请求，就会将其加入到 SYN 队列；全连接队列是指 Accept 队列，当服务端收到客户端的 <code>ACK</code>  就会将 SYN 队列对应节点放到 Accept 队列中。当队列满了，Linux 默认的操作是拒绝再接收 ACK。因为队列装不下了，但是有个问题就是，客户端发送了 ACK 就会进入 <code>ESTABLISHED</code>  状态，但是实际上服务端却没有接收。</p>\n<p>Linux 中变量 <code>tcp_abort_on_overflow</code>  为 0，就是丢掉客户端发送的数据，为 1 就会发送一个 <code>reset</code>  包给客户端。</p>\n<p><strong>所以全连接队列满了，一般解决方法就是扩大队列长度，Accept 队列长度由两个变量决定，结果式为 <code>len = min(backlog, somaxconn)</code> 。</strong></p>\n<p>半连接队列长度 <code>max_qlen_log</code>  取决于全连接队列长度 <code>len</code> 、变量 <code>max_syn_backlog</code> ： <code>max_qlen_log = 2 * min(len, max_syn_backlog)</code> 。</p>\n<p>半连接队列一般不会满，当队列中剩余长度达到某个特定值时（和 <code>max_syn_backlog</code>  有关，但是不同 Linux 版本计算方法可能不同），就不会再接收 <code>SYN</code>  了。其实当全连接队列满了，不论半连接队列如何，都不会再接收 <code>SYN</code>  了。</p>\n<p>半连接队列满了（假设遇到了 <code>SYN</code>  攻击），策略有三个：</p>\n<ul>\n<li>增大半连接队列长度，也就是增大那三个参数。</li>\n<li>打开 <code>syncookies</code> ，将该变量设置为 1 即可（0-- 关闭，1-- 队列满了打开 <code>syncookies</code> ，2-- 直接打开 <code>syncookies</code> ）。开启该功能后，不会再丢弃 <code>SYN</code>  包，而是服务器根据当前状态计算出一个值，放在 <code>SYN+ACK</code>  中发出，当客户端返回 <code>ACK</code>  报文时，取出该值校验合法性，建立连接。</li>\n<li>减少 <code>SYN+ACK</code>  重发次数，使得处于 <code>SYN_REVC</code>  状态的连接尽快断开。</li>\n</ul>\n<blockquote>\n<p>9. 谈谈 TCP 相关的参数</p>\n</blockquote>\n<p>参考链接：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MveXRWN1JaU3lGWHl2UFdfbEtodjhodw==\">https://mp.weixin.qq.com/s/ytV7RZSyFXyvPW_lKhv8hw</span></p>\n<p>这里讲的 TCP 参数与 TCP 三次握手和四次挥手优化有关。</p>\n<p>三次握手优化角度：</p>\n<ul>\n<li>客户端（发送方）：客户端行为有发送 <code>SYN</code>  和 <code>ACK</code> ，以及重发 <code>SYN</code>  和 <code>ACK</code> 。\n<ul>\n<li><code>tcp_syn_retries</code>  参数：控制重传 <code>SYN</code>  次数，每次超时时间为上次 2 倍，初始为 1s。<strong>超过次数就会断开连接</strong>。</li>\n</ul>\n</li>\n<li>服务端（接收方）：服务端行为较复杂，涉及到半连接队列和全连接队列的大小以及拒绝策略\n<ul>\n<li>重发 <code>FIN+ACK</code>  次数：由 <code>tcp_synack_retires</code>  决定</li>\n<li>半连接队列：大小由 <code>tcp_max_syn</code> 、 <code>backlog</code> 、 <code>somaxconn</code>  共同决定。可以通过增大这三个参数来增大半连接队列。同时 <code>syncookies</code>  参数控制当半连接队列满了时，生成状态值校验来避免放到半连接队列中。</li>\n<li>全连接队列：大小由 <code>backlog</code>  和 <code>somaxconn</code>  共同决定。拒绝策略由 <code>tcp_abort_on_overflow</code>  决定，0 表示丢弃 <code>ACK</code> ，不让其进入全连接队列，一般用这个，还可以解决短暂的突发网络繁忙。1 表示发送 <code>RST</code>  包使其断开连接。</li>\n</ul>\n</li>\n<li>绕过三次握手：Linux 内核 3.1 版本后，出现了 <code>Fast Open</code>  机制，通过 <code>Cookie</code>  来绕过后面的三次握手。第一次正常三次握手，但是服务端可以在第二次握手时创建 <code>Cookie</code>  并发送给客户端。之后就可以重用该 <code>TCP</code>  连接，而不需要重复建立 TCP 连接。因为后续数据发送可以携带 <code>Cookie</code> ，服务端只需要验证 <code>Cookie</code>  即可。这种的缺点就是，如果重发，还需要重发 <code>Cookie</code> 。该机制使用 <code>tcp_fastopn</code> ：\n<ul>\n<li>0 ——  <code>close</code></li>\n<li>1 ——  <code>Client</code>  打开</li>\n<li>2 ——  <code>Server</code>  打开</li>\n<li>3 —— 双方都打开</li>\n</ul>\n</li>\n</ul>\n<p>四次挥手优化角度：</p>\n<ul>\n<li>主动断开方：会进入 <code>TIME_WAIT</code>  状态，接收发送 <code>FIN</code>  和 <code>ACK</code> 。\n<ul>\n<li><code>tcp_max_orphan</code>  参数：调用 <code>close</code>  函数后，连接就变成了<strong>孤儿连接</strong>，该参数限制了最大孤儿连接数量，超过直接发送 <code>RST</code>  包断开连接。</li>\n<li><code>FIN_WAIT1</code>  状态优化： <code>tcp_orphan_retries</code>  参数 —— 表示处于 <code>FIN_WAIT1</code>  状态的 <code>FIN</code>  重传次数，超过直接关掉连接。</li>\n<li><code>FIN_WAIT2</code>  状态优化： <code>tcp_fin_timeout</code>  参数：表示孤儿连接等待 <code>FIN</code>  的最长时间，默认 60s。</li>\n<li><code>TIME_WAIT</code>  状态优化：\n<ul>\n<li><code>tcp_max_tw_buckets</code>  参数：如果处于 <code>TIME_WAIT</code>  连接超过该参数，之后的连接不再进入该状态。</li>\n<li><code>tcp_tw_reuse</code>  参数：开启后可以复用处于 <code>TIME_WAIT</code>  状态的连接，需要配合时间戳使用。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>被动断开方：\n<ul>\n<li>还是借助 <code>tcp_orphan_retires</code>  参数限定 <code>FIN</code>  重传次数。</li>\n</ul>\n</li>\n</ul>\n<p>小结：</p>\n<ul>\n<li>三次握手参数： <code>tcp_syn_retries</code> 、 <code>somaxconn</code> 、 <code>backlog</code> 、 <code>tcp_max_syn</code> 、 <code>syncookies</code> 、 <code>tcp_abort_on_overflow</code> 、 <code>tcp_fastopn</code> 。</li>\n<li>四次挥手参数： <code>tcp_max_orphan</code> 、 <code>tcp_orphan_retries</code> 、 <code>tcp_fin_timeout</code> 、 <code>tcp_max_tw_buckets</code> 、 <code>tcp_tw_reuse</code> 。</li>\n</ul>\n<blockquote>\n<p>10. 聊聊 TCP 的可靠传输机制，比如重传、拥塞、流量控制等</p>\n</blockquote>\n<ul>\n<li>\n<p><strong>重传机制</strong>： 接收方回复 ACK 用于提醒发送方应该发那个数据包，当出现数据包丢失，接收方需要重传，分为超时重传和快速重传</p>\n<ul>\n<li>\n<p>超时重传：接收方拿不到 3 这个数据包，就不发 3 的 ACK，发送方等待 3 这个 ACK 超时，再重传，一种是只重传 3（节省带宽，慢），另一种是 3，4，5（快，浪费带宽）等都重传。</p>\n</li>\n<li>\n<p>快速重传：发送方连续三次接收到同一个 ACK，则重传对应的数据报。</p>\n</li>\n</ul>\n<p>其实重传都面临一个选择：只重传这一个还是重传后边所有数据报。这就引出<strong> SACK</strong> 机制，接收方回复 SACK，SACK 会汇报收到的数据碎片，这个协议需要两边都支持。但是 SACK 并不能替代 ACK，<strong>接收方有权把已经报给发送端 SACK 里的数据给丢了</strong>。</p>\n<p><strong>SACK</strong> 有一个严重的问题，Linux 代码中，使用一个 <code>sk_buff</code>  的数据结构，简称 <code>SBK</code> ，用于存储<strong>发送、接收</strong>队列等，还有一个结构体为 <code>skb_cb</code>  用于控制缓存，记录各种<strong> TCP packet</strong> 的各种信息，如小报文的数量 <code>tcp_gso_segs</code> ，无符号两字节，最多表示 64K，SKB 会将小报文段分片累积成大报文段再发送，但是内部最多维护 17 个分片队列，每个队列最大 32KB，如果有恶意攻击者将 <code>mss</code>  设置为 8，则每个小报文段大小为 8B。<strong>SACK</strong> 机制会将许多 <code>SKB</code>  合并填满一个 <code>SKB</code> ，那么就可能出现： <code>17 * 32 * 1024 / 8 &gt; 64K</code>  导致 <code>tcp_gso_segs</code>  溢出，进入 <code>BUG_ON</code>  函数使得服务器拒绝远程连接。</p>\n</li>\n<li>\n<p><strong>滑动窗口</strong>：发送方和接收方都有窗口，接收方的滑动窗口可以使发送方根据接收方的接收能力来发送数据。确认机制为<strong>累计确认 / 累计应答</strong>，假设收到序列号为 100 的 ACK，说明 100 以前的数据都收到了。</p>\n<p>如果接收方的窗口为 0 了，也会将发送方的窗口设为 0，此时不再发送数据，直到接收方窗口恢复，此时发送一个通知消息给发送方，并等待数据。如果这个通知消息因为网络拥塞丢失了，就会导致：接收方一直等待数据，发送方一直等待通知的死锁状况。所以一旦发送方窗口被置为 0，就会每隔一段时间发送探测报文，询问接收方窗口大小。</p>\n<p><strong>Silly Window Syndrome</strong> 是一种现象，会对小的 window size 做出响应，为了避免对小的 window size 做出响应，直到有足够大的 window size 再响应，如果窗口太小，发送出去的数据甚至没有 <code>MSS</code>  高，就会先累积再发送。</p>\n</li>\n<li>\n<p><strong>拥塞处理</strong>：名词： <code>ssthresh</code>  是慢启动阈值， <code>cwnd</code>  为拥塞窗口大小。</p>\n<p>三个状态，分别是慢启动，拥塞避免和快速恢复。</p>\n<ul>\n<li><strong>慢启动</strong>： <code>cwnd</code> （拥塞窗口）一开始为 <code>1MSS</code> ，每收到 1 个 <code>ACK</code>  就 <code>+1</code> ，如果<strong>超时</strong>， <code>ssthresh=cwnd/2</code> ，并且 <code>cwnd=1</code>  重新慢启动。如果之后 <code>cwnd &gt;=  ssthresh</code>  就进入<strong>拥塞避免</strong>。如果触发快速重传，就进入<strong>快速恢复</strong>。</li>\n<li><strong>拥塞避免</strong>：每一个 <code>RTT</code>  就 <code>cwnd++</code> ，如果超时，设置 <code>ssthresh=cwnd/2, cwnd = 1</code> ，进入慢启动。如果触发快速重传，进入<strong>快速恢复</strong>。</li>\n<li><strong>快速恢复</strong>：如果超时，同样操作，进入慢启动；每次收到一个冗余 <code>ACK</code> ， <code>cwnd++</code> ，如果收到新 <code>ACK</code> ，进入<strong>拥塞避免</strong>。</li>\n</ul>\n<p>进入<strong>快速恢复</strong>之前，设置参数为 <code>ssthresh=cwnd/2, cwnd = ssthresh + 3</code> 。</p>\n<p><strong>这里的 <code>RTT</code>  是指一个窗口的数据全部发送出去，又全部收到 <code>ACK</code>  的时间，而不是某一个报文的往返时间</strong>。</p>\n</li>\n</ul>\n<blockquote>\n<p>11.DNS 劫持和 DNS 污染</p>\n</blockquote>\n<p><strong>DNS 劫持</strong>：劫持了 DNS 服务器，通过某些手段取得某域名的解析记录控制权，进而修改此域名的解析结果，导致对该域名的访问由原 IP 地址转入到修改后的指定 IP。</p>\n<p><strong>DNS 污染</strong>：通过对 UDP 端口 53 上的 DNS 查询进行入侵检测，一经发现与关键词相匹配的请求则立即伪装成目标域名的解析服务器（NS，Name Server）给查询者返回虚假结果。很难靠个人设置解决，使用 VPN 是一个方法</p>\n<blockquote>\n<p>12. 聊聊 IP 协议，它和 MAC 地址有什么区别，IPV4 和 IPV6 呢？</p>\n</blockquote>\n<p>IP 协议用于唯一标识网络设备，属于网络层协议，传输层将数据包传到网络层后，会为数据加上 IP 首部。 <code>MAC</code>  属于链路层，用于标识下一跳的网络设备的物理地址，数据从源主机到目的主机的过程中， <code>MAC</code>  首部每经过一个路由器都会变换，而 IP 地址不会变换。</p>\n<p><code>IPv4</code>  地址由 32 位组成，以前会根据前几位将其分为 <code>ABCDE</code>  类地址，但是分类地址的局限性太多，比如 C 类 IP 数量太少，而 A 类 IP 数量有太多，所以采用了无分类 IP 地址，通过子网掩码和 IP 地址做 ** <code>&amp;</code>  运算<strong>来确定</strong>网络号、子网号 **。在路由控制中，目的地址与路由表中的子网掩码运算并比较网络号，从而进行路由转发。</p>\n<p>IP 协议因为不能重组分片数据，所以分片会导致严重的性能损耗，一个分片丢失了，就要重发整个 IP 数据报，所以通过引入 <code>MSS</code>  将分片操作交给 <code>TCP</code>  处理。</p>\n<p>IPv6 相对于 IPv4 的改进：</p>\n<ul>\n<li>取消了首部校验和字段：因为数据链路层和传输层都会校验</li>\n<li>取消分片 / 重组相关字段，这种操作只允许源 / 目标主机。</li>\n<li>使用了 128 位，16 进制，极大扩充了 IP 数量</li>\n</ul>\n",
            "tags": [
                "八股文"
            ]
        }
    ]
}